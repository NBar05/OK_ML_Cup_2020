{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>–¥–≤–æ—Ä–Ω–∏–∫–∞ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å!</td>\n",
       "      <td>–¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂</td>\n",
       "      <td>–¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>–º–æ—è —Å—Ç–∞—Ä—à–∞—è –Ω–µ–¥–µ–ª—é —à–∏–ø–µ–ª–∞, –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–ª–∞ –ø–æ–¥–∫–∏–¥...</td>\n",
       "      <td>–º–æ—è —Å—Ç–∞—Ä—à –Ω–µ–¥–µ–ª —à–∏–ø–µ–ª –Ω–µ –ø—Ä–∏–Ω–∏–º–∞ –ø–æ–¥–∫–∏–¥—ã—à –∫–æ—Ç–æ...</td>\n",
       "      <td>–º–æ–π —Å—Ç–∞—Ä—à–∏–π –Ω–µ–¥–µ–ª—è —à–∏–ø–µ—Ç—å –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –ø–æ–¥–∫–∏–¥—ã...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤–∞–º–∏ —Å–æ–≥–ª–∞—Å–Ω–∞!</td>\n",
       "      <td>–ø–æ–ª–Ω–æ—Å—Ç —Å –≤–∞–º —Å–æ–≥–ª–∞—Å–Ω</td>\n",
       "      <td>–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤—ã —Å–æ–≥–ª–∞—Å–Ω—ã–π</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     –¥–≤–æ—Ä–Ω–∏–∫–∞ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å!   \n",
       "1   6812  –º–æ—è —Å—Ç–∞—Ä—à–∞—è –Ω–µ–¥–µ–ª—é —à–∏–ø–µ–ª–∞, –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–ª–∞ –ø–æ–¥–∫–∏–¥...   \n",
       "2   6256                         –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤–∞–º–∏ —Å–æ–≥–ª–∞—Å–Ω–∞!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          –¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂   \n",
       "1  –º–æ—è —Å—Ç–∞—Ä—à –Ω–µ–¥–µ–ª —à–∏–ø–µ–ª –Ω–µ –ø—Ä–∏–Ω–∏–º–∞ –ø–æ–¥–∫–∏–¥—ã—à –∫–æ—Ç–æ...   \n",
       "2                              –ø–æ–ª–Ω–æ—Å—Ç —Å –≤–∞–º —Å–æ–≥–ª–∞—Å–Ω   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       –¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å       0       1       0   \n",
       "1  –º–æ–π —Å—Ç–∞—Ä—à–∏–π –Ω–µ–¥–µ–ª—è —à–∏–ø–µ—Ç—å –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –ø–æ–¥–∫–∏–¥—ã...       1       0       0   \n",
       "2                           –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤—ã —Å–æ–≥–ª–∞—Å–Ω—ã–π       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 8), (18547, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_tdidf_logit_label(label):\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def hyperopt_tdidf_logit(params):\n",
    "        space_trans = {key: value for key, value in params.items() if (key != 'C') and (key != 'stemming')}\n",
    "\n",
    "        trans = TfidfVectorizer(**space_trans)\n",
    "        clf = LogisticRegression(class_weight = 'balanced', C = params['C'])\n",
    "\n",
    "        pipe = Pipeline([('trans', trans), ('clf', clf)])\n",
    "\n",
    "        X = XY_train.text_stemmed if params['stemming'] else XY_train.text\n",
    "\n",
    "        score = cross_val_score(estimator = pipe, X = X, y = XY_train[label],\n",
    "                                cv = StratifiedKFold(n_splits = 5), scoring = 'average_precision')\n",
    "\n",
    "        score_mean = score.mean()\n",
    "\n",
    "        return -score_mean\n",
    "\n",
    "    space_tfidf_logit = {\n",
    "        'stemming': hp.choice('stemming', [True, False]),    \n",
    "#         'stop_words': hp.choice('stop_words', [stopWords, None]),\n",
    "        'ngram_range': hp.choice('ngram_range', [(1, 1), (1, 2)]),\n",
    "        'min_df': hp.uniform('min_df', 0.00, 0.05),\n",
    "        'max_df': hp.uniform('max_df', 0.95, 1.00),\n",
    "        'C': hp.uniform('C', 0.01, 100)\n",
    "    }\n",
    "    \n",
    "    best = fmin(fn = hyperopt_tdidf_logit, space = space_tfidf_logit, algo = tpe.suggest, max_evals = 30)\n",
    "    \n",
    "    best['stemming'] = [True, False][best['stemming']]\n",
    "#     best['stop_words'] = [stopWords, None][best['stop_words']]\n",
    "    best['ngram_range'] = [(1, 1), (1, 2)][best['ngram_range']]\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [10:09<00:00, 20.32s/trial, best loss: -0.9899153336125238]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [08:12<00:00, 16.42s/trial, best loss: -0.8455040744324431]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [09:36<00:00, 19.21s/trial, best loss: -0.7539220637762643] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [12:21<00:00, 24.70s/trial, best loss: -0.7202495063035603] \n"
     ]
    }
   ],
   "source": [
    "best_normal = hyperopt_tdidf_logit_label('normal')\n",
    "best_insult = hyperopt_tdidf_logit_label('insult')\n",
    "best_threat = hyperopt_tdidf_logit_label('threat')\n",
    "best_obscenity = hyperopt_tdidf_logit_label('obscenity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 26.69055673760855,\n",
       " 'max_df': 0.9628048616138088,\n",
       " 'min_df': 0.00011950169636565193,\n",
       " 'ngram_range': (1, 1),\n",
       " 'stemming': True,\n",
       " 'stop_words': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 38.43711032544301,\n",
       " 'max_df': 0.9761293205934343,\n",
       " 'min_df': 0.0001306429356985548,\n",
       " 'ngram_range': (1, 1),\n",
       " 'stemming': False,\n",
       " 'stop_words': ['–∏',\n",
       "  '–≤',\n",
       "  '–≤–æ',\n",
       "  '–Ω–µ',\n",
       "  '—á—Ç–æ',\n",
       "  '–æ–Ω',\n",
       "  '–Ω–∞',\n",
       "  '—è',\n",
       "  '—Å',\n",
       "  '—Å–æ',\n",
       "  '–∫–∞–∫',\n",
       "  '–∞',\n",
       "  '—Ç–æ',\n",
       "  '–≤—Å–µ',\n",
       "  '–æ–Ω–∞',\n",
       "  '—Ç–∞–∫',\n",
       "  '–µ–≥–æ',\n",
       "  '–Ω–æ',\n",
       "  '–¥–∞',\n",
       "  '—Ç—ã',\n",
       "  '–∫',\n",
       "  '—É',\n",
       "  '–∂–µ',\n",
       "  '–≤—ã',\n",
       "  '–∑–∞',\n",
       "  '–±—ã',\n",
       "  '–ø–æ',\n",
       "  '—Ç–æ–ª—å–∫–æ',\n",
       "  '–µ–µ',\n",
       "  '–º–Ω–µ',\n",
       "  '–±—ã–ª–æ',\n",
       "  '–≤–æ—Ç',\n",
       "  '–æ—Ç',\n",
       "  '–º–µ–Ω—è',\n",
       "  '–µ—â–µ',\n",
       "  '–Ω–µ—Ç',\n",
       "  '–æ',\n",
       "  '–∏–∑',\n",
       "  '–µ–º—É',\n",
       "  '—Ç–µ–ø–µ—Ä—å',\n",
       "  '–∫–æ–≥–¥–∞',\n",
       "  '–¥–∞–∂–µ',\n",
       "  '–Ω—É',\n",
       "  '–≤–¥—Ä—É–≥',\n",
       "  '–ª–∏',\n",
       "  '–µ—Å–ª–∏',\n",
       "  '—É–∂–µ',\n",
       "  '–∏–ª–∏',\n",
       "  '–Ω–∏',\n",
       "  '–±—ã—Ç—å',\n",
       "  '–±—ã–ª',\n",
       "  '–Ω–µ–≥–æ',\n",
       "  '–¥–æ',\n",
       "  '–≤–∞—Å',\n",
       "  '–Ω–∏–±—É–¥—å',\n",
       "  '–æ–ø—è—Ç—å',\n",
       "  '—É–∂',\n",
       "  '–≤–∞–º',\n",
       "  '–≤–µ–¥—å',\n",
       "  '—Ç–∞–º',\n",
       "  '–ø–æ—Ç–æ–º',\n",
       "  '—Å–µ–±—è',\n",
       "  '–Ω–∏—á–µ–≥–æ',\n",
       "  '–µ–π',\n",
       "  '–º–æ–∂–µ—Ç',\n",
       "  '–æ–Ω–∏',\n",
       "  '—Ç—É—Ç',\n",
       "  '–≥–¥–µ',\n",
       "  '–µ—Å—Ç—å',\n",
       "  '–Ω–∞–¥–æ',\n",
       "  '–Ω–µ–π',\n",
       "  '–¥–ª—è',\n",
       "  '–º—ã',\n",
       "  '—Ç–µ–±—è',\n",
       "  '–∏—Ö',\n",
       "  '—á–µ–º',\n",
       "  '–±—ã–ª–∞',\n",
       "  '—Å–∞–º',\n",
       "  '—á—Ç–æ–±',\n",
       "  '–±–µ–∑',\n",
       "  '–±—É–¥—Ç–æ',\n",
       "  '—á–µ–≥–æ',\n",
       "  '—Ä–∞–∑',\n",
       "  '—Ç–æ–∂–µ',\n",
       "  '—Å–µ–±–µ',\n",
       "  '–ø–æ–¥',\n",
       "  '–±—É–¥–µ—Ç',\n",
       "  '–∂',\n",
       "  '—Ç–æ–≥–¥–∞',\n",
       "  '–∫—Ç–æ',\n",
       "  '—ç—Ç–æ—Ç',\n",
       "  '—Ç–æ–≥–æ',\n",
       "  '–ø–æ—Ç–æ–º—É',\n",
       "  '—ç—Ç–æ–≥–æ',\n",
       "  '–∫–∞–∫–æ–π',\n",
       "  '—Å–æ–≤—Å–µ–º',\n",
       "  '–Ω–∏–º',\n",
       "  '–∑–¥–µ—Å—å',\n",
       "  '—ç—Ç–æ–º',\n",
       "  '–æ–¥–∏–Ω',\n",
       "  '–ø–æ—á—Ç–∏',\n",
       "  '–º–æ–π',\n",
       "  '—Ç–µ–º',\n",
       "  '—á—Ç–æ–±—ã',\n",
       "  '–Ω–µ–µ',\n",
       "  '—Å–µ–π—á–∞—Å',\n",
       "  '–±—ã–ª–∏',\n",
       "  '–∫—É–¥–∞',\n",
       "  '–∑–∞—á–µ–º',\n",
       "  '–≤—Å–µ—Ö',\n",
       "  '–Ω–∏–∫–æ–≥–¥–∞',\n",
       "  '–º–æ–∂–Ω–æ',\n",
       "  '–ø—Ä–∏',\n",
       "  '–Ω–∞–∫–æ–Ω–µ—Ü',\n",
       "  '–¥–≤–∞',\n",
       "  '–æ–±',\n",
       "  '–¥—Ä—É–≥–æ–π',\n",
       "  '—Ö–æ—Ç—å',\n",
       "  '–ø–æ—Å–ª–µ',\n",
       "  '–Ω–∞–¥',\n",
       "  '–±–æ–ª—å—à–µ',\n",
       "  '—Ç–æ—Ç',\n",
       "  '—á–µ—Ä–µ–∑',\n",
       "  '—ç—Ç–∏',\n",
       "  '–Ω–∞—Å',\n",
       "  '–ø—Ä–æ',\n",
       "  '–≤—Å–µ–≥–æ',\n",
       "  '–Ω–∏—Ö',\n",
       "  '–∫–∞–∫–∞—è',\n",
       "  '–º–Ω–æ–≥–æ',\n",
       "  '—Ä–∞–∑–≤–µ',\n",
       "  '—Ç—Ä–∏',\n",
       "  '—ç—Ç—É',\n",
       "  '–º–æ—è',\n",
       "  '–≤–ø—Ä–æ—á–µ–º',\n",
       "  '—Ö–æ—Ä–æ—à–æ',\n",
       "  '—Å–≤–æ—é',\n",
       "  '—ç—Ç–æ–π',\n",
       "  '–ø–µ—Ä–µ–¥',\n",
       "  '–∏–Ω–æ–≥–¥–∞',\n",
       "  '–ª—É—á—à–µ',\n",
       "  '—á—É—Ç—å',\n",
       "  '—Ç–æ–º',\n",
       "  '–Ω–µ–ª—å–∑—è',\n",
       "  '—Ç–∞–∫–æ–π',\n",
       "  '–∏–º',\n",
       "  '–±–æ–ª–µ–µ',\n",
       "  '–≤—Å–µ–≥–¥–∞',\n",
       "  '–∫–æ–Ω–µ—á–Ω–æ',\n",
       "  '–≤—Å—é',\n",
       "  '–º–µ–∂–¥—É']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 12.153337935599467,\n",
       " 'max_df': 0.9699701370487585,\n",
       " 'min_df': 0.00020556610553198323,\n",
       " 'ngram_range': (1, 2),\n",
       " 'stemming': True,\n",
       " 'stop_words': ['–∏',\n",
       "  '–≤',\n",
       "  '–≤–æ',\n",
       "  '–Ω–µ',\n",
       "  '—á—Ç–æ',\n",
       "  '–æ–Ω',\n",
       "  '–Ω–∞',\n",
       "  '—è',\n",
       "  '—Å',\n",
       "  '—Å–æ',\n",
       "  '–∫–∞–∫',\n",
       "  '–∞',\n",
       "  '—Ç–æ',\n",
       "  '–≤—Å–µ',\n",
       "  '–æ–Ω–∞',\n",
       "  '—Ç–∞–∫',\n",
       "  '–µ–≥–æ',\n",
       "  '–Ω–æ',\n",
       "  '–¥–∞',\n",
       "  '—Ç—ã',\n",
       "  '–∫',\n",
       "  '—É',\n",
       "  '–∂–µ',\n",
       "  '–≤—ã',\n",
       "  '–∑–∞',\n",
       "  '–±—ã',\n",
       "  '–ø–æ',\n",
       "  '—Ç–æ–ª—å–∫–æ',\n",
       "  '–µ–µ',\n",
       "  '–º–Ω–µ',\n",
       "  '–±—ã–ª–æ',\n",
       "  '–≤–æ—Ç',\n",
       "  '–æ—Ç',\n",
       "  '–º–µ–Ω—è',\n",
       "  '–µ—â–µ',\n",
       "  '–Ω–µ—Ç',\n",
       "  '–æ',\n",
       "  '–∏–∑',\n",
       "  '–µ–º—É',\n",
       "  '—Ç–µ–ø–µ—Ä—å',\n",
       "  '–∫–æ–≥–¥–∞',\n",
       "  '–¥–∞–∂–µ',\n",
       "  '–Ω—É',\n",
       "  '–≤–¥—Ä—É–≥',\n",
       "  '–ª–∏',\n",
       "  '–µ—Å–ª–∏',\n",
       "  '—É–∂–µ',\n",
       "  '–∏–ª–∏',\n",
       "  '–Ω–∏',\n",
       "  '–±—ã—Ç—å',\n",
       "  '–±—ã–ª',\n",
       "  '–Ω–µ–≥–æ',\n",
       "  '–¥–æ',\n",
       "  '–≤–∞—Å',\n",
       "  '–Ω–∏–±—É–¥—å',\n",
       "  '–æ–ø—è—Ç—å',\n",
       "  '—É–∂',\n",
       "  '–≤–∞–º',\n",
       "  '–≤–µ–¥—å',\n",
       "  '—Ç–∞–º',\n",
       "  '–ø–æ—Ç–æ–º',\n",
       "  '—Å–µ–±—è',\n",
       "  '–Ω–∏—á–µ–≥–æ',\n",
       "  '–µ–π',\n",
       "  '–º–æ–∂–µ—Ç',\n",
       "  '–æ–Ω–∏',\n",
       "  '—Ç—É—Ç',\n",
       "  '–≥–¥–µ',\n",
       "  '–µ—Å—Ç—å',\n",
       "  '–Ω–∞–¥–æ',\n",
       "  '–Ω–µ–π',\n",
       "  '–¥–ª—è',\n",
       "  '–º—ã',\n",
       "  '—Ç–µ–±—è',\n",
       "  '–∏—Ö',\n",
       "  '—á–µ–º',\n",
       "  '–±—ã–ª–∞',\n",
       "  '—Å–∞–º',\n",
       "  '—á—Ç–æ–±',\n",
       "  '–±–µ–∑',\n",
       "  '–±—É–¥—Ç–æ',\n",
       "  '—á–µ–≥–æ',\n",
       "  '—Ä–∞–∑',\n",
       "  '—Ç–æ–∂–µ',\n",
       "  '—Å–µ–±–µ',\n",
       "  '–ø–æ–¥',\n",
       "  '–±—É–¥–µ—Ç',\n",
       "  '–∂',\n",
       "  '—Ç–æ–≥–¥–∞',\n",
       "  '–∫—Ç–æ',\n",
       "  '—ç—Ç–æ—Ç',\n",
       "  '—Ç–æ–≥–æ',\n",
       "  '–ø–æ—Ç–æ–º—É',\n",
       "  '—ç—Ç–æ–≥–æ',\n",
       "  '–∫–∞–∫–æ–π',\n",
       "  '—Å–æ–≤—Å–µ–º',\n",
       "  '–Ω–∏–º',\n",
       "  '–∑–¥–µ—Å—å',\n",
       "  '—ç—Ç–æ–º',\n",
       "  '–æ–¥–∏–Ω',\n",
       "  '–ø–æ—á—Ç–∏',\n",
       "  '–º–æ–π',\n",
       "  '—Ç–µ–º',\n",
       "  '—á—Ç–æ–±—ã',\n",
       "  '–Ω–µ–µ',\n",
       "  '—Å–µ–π—á–∞—Å',\n",
       "  '–±—ã–ª–∏',\n",
       "  '–∫—É–¥–∞',\n",
       "  '–∑–∞—á–µ–º',\n",
       "  '–≤—Å–µ—Ö',\n",
       "  '–Ω–∏–∫–æ–≥–¥–∞',\n",
       "  '–º–æ–∂–Ω–æ',\n",
       "  '–ø—Ä–∏',\n",
       "  '–Ω–∞–∫–æ–Ω–µ—Ü',\n",
       "  '–¥–≤–∞',\n",
       "  '–æ–±',\n",
       "  '–¥—Ä—É–≥–æ–π',\n",
       "  '—Ö–æ—Ç—å',\n",
       "  '–ø–æ—Å–ª–µ',\n",
       "  '–Ω–∞–¥',\n",
       "  '–±–æ–ª—å—à–µ',\n",
       "  '—Ç–æ—Ç',\n",
       "  '—á–µ—Ä–µ–∑',\n",
       "  '—ç—Ç–∏',\n",
       "  '–Ω–∞—Å',\n",
       "  '–ø—Ä–æ',\n",
       "  '–≤—Å–µ–≥–æ',\n",
       "  '–Ω–∏—Ö',\n",
       "  '–∫–∞–∫–∞—è',\n",
       "  '–º–Ω–æ–≥–æ',\n",
       "  '—Ä–∞–∑–≤–µ',\n",
       "  '—Ç—Ä–∏',\n",
       "  '—ç—Ç—É',\n",
       "  '–º–æ—è',\n",
       "  '–≤–ø—Ä–æ—á–µ–º',\n",
       "  '—Ö–æ—Ä–æ—à–æ',\n",
       "  '—Å–≤–æ—é',\n",
       "  '—ç—Ç–æ–π',\n",
       "  '–ø–µ—Ä–µ–¥',\n",
       "  '–∏–Ω–æ–≥–¥–∞',\n",
       "  '–ª—É—á—à–µ',\n",
       "  '—á—É—Ç—å',\n",
       "  '—Ç–æ–º',\n",
       "  '–Ω–µ–ª—å–∑—è',\n",
       "  '—Ç–∞–∫–æ–π',\n",
       "  '–∏–º',\n",
       "  '–±–æ–ª–µ–µ',\n",
       "  '–≤—Å–µ–≥–¥–∞',\n",
       "  '–∫–æ–Ω–µ—á–Ω–æ',\n",
       "  '–≤—Å—é',\n",
       "  '–º–µ–∂–¥—É']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 76.39223651587547,\n",
       " 'max_df': 0.9690781859494049,\n",
       " 'min_df': 1.2200877751358113e-05,\n",
       " 'ngram_range': (1, 1),\n",
       " 'stemming': False,\n",
       " 'stop_words': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_obscenity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_normal = {'C': 73.52580652715072,\n",
    "#                'max_df': 0.9696315615375243,\n",
    "#                'min_df': 2.1701497893422727e-05,\n",
    "#                'ngram_range': (1, 2),\n",
    "#                'stemming': False,\n",
    "#                'stop_words': None\n",
    "#               }\n",
    "# Average precision score train: 0.9996649882629408 from another notebook\n",
    "# Average precision score test: 0.9924950275198423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def cook_algo(XY, label, params):\n",
    "    space_trans = {key: value for key, value in params.items() if (key != 'C') and (key != 'stemming')}\n",
    "    \n",
    "    trans = TfidfVectorizer(**space_trans)\n",
    "    clf = LogisticRegression(class_weight = 'balanced', C = params['C'])\n",
    "    \n",
    "    X = XY.text_stemmed if params['stemming'] else XY.text\n",
    "    y = XY[label]\n",
    "        \n",
    "    pipe = Pipeline([('trans', TfidfVectorizer(**space_trans)), \n",
    "                     ('clf', LogisticRegression(C = params['C']))])\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    print(f'Average precision score: {average_precision_score(y_score = pipe.predict_proba(X)[:, 1], y_true = y)}')\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(XY, label, params, pipeline):\n",
    "    X = XY.text_stemmed if params['stemming'] else XY.text\n",
    "    y = XY[label]\n",
    "    \n",
    "    y_pred = pipeline.predict_proba(X)[:, 1]\n",
    "    print(f'Average precision score: {average_precision_score(y_score = y_pred, y_true = y)}')\n",
    "    \n",
    "    return y_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9962720089665845\n",
      "Average precision score: 0.9286916279788466\n",
      "Average precision score: 0.8754930896826478\n",
      "Average precision score: 0.9933882121816242\n"
     ]
    }
   ],
   "source": [
    "pipe_normal = cook_algo(XY_train, 'normal', best_normal)\n",
    "pipe_insult = cook_algo(XY_train, 'insult', best_insult)\n",
    "pipe_threat = cook_algo(XY_train, 'threat', best_threat)\n",
    "pipe_obscenity = cook_algo(XY_train, 'obscenity', best_obscenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9962720089665845\n",
      "Average precision score: 0.9909018049370828\n"
     ]
    }
   ],
   "source": [
    "preds_normal_train = my_predict(XY_train, 'normal', best_normal, pipe_normal)\n",
    "preds_normal_test = my_predict(XY_test, 'normal', best_normal, pipe_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9286916279788466\n",
      "Average precision score: 0.8672494906009367\n"
     ]
    }
   ],
   "source": [
    "preds_insult_train = my_predict(XY_train, 'insult', best_insult, pipe_insult)\n",
    "preds_insult_test = my_predict(XY_test, 'insult', best_insult, pipe_insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.8754930896826478\n",
      "Average precision score: 0.7869322209839801\n"
     ]
    }
   ],
   "source": [
    "preds_threat_train = my_predict(XY_train, 'threat', best_threat, pipe_threat)\n",
    "preds_threat_test = my_predict(XY_test, 'threat', best_threat, pipe_threat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9933882121816242\n",
      "Average precision score: 0.7647738738449493\n"
     ]
    }
   ],
   "source": [
    "preds_obscenity_train = my_predict(XY_train, 'obscenity', best_obscenity, pipe_obscenity)\n",
    "preds_obscenity_test = my_predict(XY_test, 'obscenity', best_obscenity, pipe_obscenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>–∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—å!!!üòç</td>\n",
       "      <td>–∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—åüòç</td>\n",
       "      <td>–∫–∞–∫–æ–π –ø—Ä–µ–ª–µ—Å—Ç—åüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>–∫–∞–∞–ª –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å—é?</td>\n",
       "      <td>–∫–∞–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤</td>\n",
       "      <td>–∫–∞–∞–ª–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>–≥–Ω–æ–π–Ω—ã–µ –ø–∏–¥–æ—Ä—ã –∞–ª–ª—ã –æ–Ω–∏</td>\n",
       "      <td>–≥–Ω–æ–π–Ω –ø–∏–¥–æ—Ä –∞–ª–ª –æ–Ω–∏</td>\n",
       "      <td>–≥–Ω–æ–π–Ω—ã–π –ø–∏–¥–æ—Ä –∞–ª–ª–∞ –æ–Ω–∏</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     text         text_stemmed  \\\n",
       "0  167315       –∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—å!!!üòç      –∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—åüòç   \n",
       "1  224546  –∫–∞–∞–ª –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å—é?  –∫–∞–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤   \n",
       "2  241309  –≥–Ω–æ–π–Ω—ã–µ –ø–∏–¥–æ—Ä—ã –∞–ª–ª—ã –æ–Ω–∏  –≥–Ω–æ–π–Ω –ø–∏–¥–æ—Ä –∞–ª–ª –æ–Ω–∏   \n",
       "\n",
       "          text_lemmatised  \n",
       "0         –∫–∞–∫–æ–π –ø—Ä–µ–ª–µ—Å—Ç—åüòç  \n",
       "1  –∫–∞–∞–ª–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å  \n",
       "2  –≥–Ω–æ–π–Ω—ã–π –ø–∏–¥–æ—Ä –∞–ª–ª–∞ –æ–Ω–∏  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)\n",
    "X_final_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.hstack([predict_with_aka_bagging(algs_final[label], X_final_test, label).reshape(-1, 1)\n",
    "#                          for label in list(algs_final.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_predictions = pd.concat([pd.DataFrame(X_final_test.id.values, columns = ['id']),\n",
    "#                                pd.DataFrame(predictions, columns = list(algs_final.keys()))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = final_predictions.loc[:, ['id', 'normal', 'insult', 'obscenity', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('result', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
