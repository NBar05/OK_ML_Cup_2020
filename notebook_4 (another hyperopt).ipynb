{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>дворника надо тоже уничтожить!</td>\n",
       "      <td>дворник надо тоже уничтож</td>\n",
       "      <td>дворник надо тоже уничтожить</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>моя старшая неделю шипела, не принимала подкид...</td>\n",
       "      <td>моя старш недел шипел не принима подкидыш кото...</td>\n",
       "      <td>мой старший неделя шипеть не принимать подкиды...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>полностью с вами согласна!</td>\n",
       "      <td>полност с вам согласн</td>\n",
       "      <td>полностью с вы согласный</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     дворника надо тоже уничтожить!   \n",
       "1   6812  моя старшая неделю шипела, не принимала подкид...   \n",
       "2   6256                         полностью с вами согласна!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          дворник надо тоже уничтож   \n",
       "1  моя старш недел шипел не принима подкидыш кото...   \n",
       "2                              полност с вам согласн   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       дворник надо тоже уничтожить       0       1       0   \n",
       "1  мой старший неделя шипеть не принимать подкиды...       1       0       0   \n",
       "2                           полностью с вы согласный       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 8), (18547, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_tdidf_logit_label(label):\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def hyperopt_tdidf_logit(params):\n",
    "        space_trans = {key: value for key, value in params.items() if (key != 'C') and (key != 'stemming')}\n",
    "\n",
    "        trans = TfidfVectorizer(**space_trans)\n",
    "        clf = LogisticRegression(class_weight = 'balanced', C = params['C'])\n",
    "\n",
    "        pipe = Pipeline([('trans', trans), ('clf', clf)])\n",
    "\n",
    "        X = XY_train.text_stemmed if params['stemming'] else XY_train.text\n",
    "\n",
    "        score = cross_val_score(estimator = pipe, X = X, y = XY_train[label],\n",
    "                                cv = StratifiedKFold(n_splits = 5), scoring = 'average_precision')\n",
    "\n",
    "        score_mean = score.mean()\n",
    "\n",
    "        return -score_mean\n",
    "\n",
    "    space_tfidf_logit = {\n",
    "        'stemming': hp.choice('stemming', [True, False]),    \n",
    "#         'stop_words': hp.choice('stop_words', [stopWords, None]),\n",
    "        'ngram_range': hp.choice('ngram_range', [(1, 1), (1, 2)]),\n",
    "        'min_df': hp.uniform('min_df', 0.00, 0.05),\n",
    "        'max_df': hp.uniform('max_df', 0.95, 1.00),\n",
    "        'C': hp.uniform('C', 0.01, 100)\n",
    "    }\n",
    "    \n",
    "    best = fmin(fn = hyperopt_tdidf_logit, space = space_tfidf_logit, algo = tpe.suggest, max_evals = 30)\n",
    "    \n",
    "    best['stemming'] = [True, False][best['stemming']]\n",
    "#     best['stop_words'] = [stopWords, None][best['stop_words']]\n",
    "    best['ngram_range'] = [(1, 1), (1, 2)][best['ngram_range']]\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [10:09<00:00, 20.32s/trial, best loss: -0.9899153336125238]\n",
      "100%|██████████| 30/30 [08:12<00:00, 16.42s/trial, best loss: -0.8455040744324431]\n",
      "100%|██████████| 30/30 [09:36<00:00, 19.21s/trial, best loss: -0.7539220637762643] \n",
      "100%|██████████| 30/30 [12:21<00:00, 24.70s/trial, best loss: -0.7202495063035603] \n"
     ]
    }
   ],
   "source": [
    "best_normal = hyperopt_tdidf_logit_label('normal')\n",
    "best_insult = hyperopt_tdidf_logit_label('insult')\n",
    "best_threat = hyperopt_tdidf_logit_label('threat')\n",
    "best_obscenity = hyperopt_tdidf_logit_label('obscenity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 26.69055673760855,\n",
       " 'max_df': 0.9628048616138088,\n",
       " 'min_df': 0.00011950169636565193,\n",
       " 'ngram_range': (1, 1),\n",
       " 'stemming': True,\n",
       " 'stop_words': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 38.43711032544301,\n",
       " 'max_df': 0.9761293205934343,\n",
       " 'min_df': 0.0001306429356985548,\n",
       " 'ngram_range': (1, 1),\n",
       " 'stemming': False,\n",
       " 'stop_words': ['и',\n",
       "  'в',\n",
       "  'во',\n",
       "  'не',\n",
       "  'что',\n",
       "  'он',\n",
       "  'на',\n",
       "  'я',\n",
       "  'с',\n",
       "  'со',\n",
       "  'как',\n",
       "  'а',\n",
       "  'то',\n",
       "  'все',\n",
       "  'она',\n",
       "  'так',\n",
       "  'его',\n",
       "  'но',\n",
       "  'да',\n",
       "  'ты',\n",
       "  'к',\n",
       "  'у',\n",
       "  'же',\n",
       "  'вы',\n",
       "  'за',\n",
       "  'бы',\n",
       "  'по',\n",
       "  'только',\n",
       "  'ее',\n",
       "  'мне',\n",
       "  'было',\n",
       "  'вот',\n",
       "  'от',\n",
       "  'меня',\n",
       "  'еще',\n",
       "  'нет',\n",
       "  'о',\n",
       "  'из',\n",
       "  'ему',\n",
       "  'теперь',\n",
       "  'когда',\n",
       "  'даже',\n",
       "  'ну',\n",
       "  'вдруг',\n",
       "  'ли',\n",
       "  'если',\n",
       "  'уже',\n",
       "  'или',\n",
       "  'ни',\n",
       "  'быть',\n",
       "  'был',\n",
       "  'него',\n",
       "  'до',\n",
       "  'вас',\n",
       "  'нибудь',\n",
       "  'опять',\n",
       "  'уж',\n",
       "  'вам',\n",
       "  'ведь',\n",
       "  'там',\n",
       "  'потом',\n",
       "  'себя',\n",
       "  'ничего',\n",
       "  'ей',\n",
       "  'может',\n",
       "  'они',\n",
       "  'тут',\n",
       "  'где',\n",
       "  'есть',\n",
       "  'надо',\n",
       "  'ней',\n",
       "  'для',\n",
       "  'мы',\n",
       "  'тебя',\n",
       "  'их',\n",
       "  'чем',\n",
       "  'была',\n",
       "  'сам',\n",
       "  'чтоб',\n",
       "  'без',\n",
       "  'будто',\n",
       "  'чего',\n",
       "  'раз',\n",
       "  'тоже',\n",
       "  'себе',\n",
       "  'под',\n",
       "  'будет',\n",
       "  'ж',\n",
       "  'тогда',\n",
       "  'кто',\n",
       "  'этот',\n",
       "  'того',\n",
       "  'потому',\n",
       "  'этого',\n",
       "  'какой',\n",
       "  'совсем',\n",
       "  'ним',\n",
       "  'здесь',\n",
       "  'этом',\n",
       "  'один',\n",
       "  'почти',\n",
       "  'мой',\n",
       "  'тем',\n",
       "  'чтобы',\n",
       "  'нее',\n",
       "  'сейчас',\n",
       "  'были',\n",
       "  'куда',\n",
       "  'зачем',\n",
       "  'всех',\n",
       "  'никогда',\n",
       "  'можно',\n",
       "  'при',\n",
       "  'наконец',\n",
       "  'два',\n",
       "  'об',\n",
       "  'другой',\n",
       "  'хоть',\n",
       "  'после',\n",
       "  'над',\n",
       "  'больше',\n",
       "  'тот',\n",
       "  'через',\n",
       "  'эти',\n",
       "  'нас',\n",
       "  'про',\n",
       "  'всего',\n",
       "  'них',\n",
       "  'какая',\n",
       "  'много',\n",
       "  'разве',\n",
       "  'три',\n",
       "  'эту',\n",
       "  'моя',\n",
       "  'впрочем',\n",
       "  'хорошо',\n",
       "  'свою',\n",
       "  'этой',\n",
       "  'перед',\n",
       "  'иногда',\n",
       "  'лучше',\n",
       "  'чуть',\n",
       "  'том',\n",
       "  'нельзя',\n",
       "  'такой',\n",
       "  'им',\n",
       "  'более',\n",
       "  'всегда',\n",
       "  'конечно',\n",
       "  'всю',\n",
       "  'между']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 12.153337935599467,\n",
       " 'max_df': 0.9699701370487585,\n",
       " 'min_df': 0.00020556610553198323,\n",
       " 'ngram_range': (1, 2),\n",
       " 'stemming': True,\n",
       " 'stop_words': ['и',\n",
       "  'в',\n",
       "  'во',\n",
       "  'не',\n",
       "  'что',\n",
       "  'он',\n",
       "  'на',\n",
       "  'я',\n",
       "  'с',\n",
       "  'со',\n",
       "  'как',\n",
       "  'а',\n",
       "  'то',\n",
       "  'все',\n",
       "  'она',\n",
       "  'так',\n",
       "  'его',\n",
       "  'но',\n",
       "  'да',\n",
       "  'ты',\n",
       "  'к',\n",
       "  'у',\n",
       "  'же',\n",
       "  'вы',\n",
       "  'за',\n",
       "  'бы',\n",
       "  'по',\n",
       "  'только',\n",
       "  'ее',\n",
       "  'мне',\n",
       "  'было',\n",
       "  'вот',\n",
       "  'от',\n",
       "  'меня',\n",
       "  'еще',\n",
       "  'нет',\n",
       "  'о',\n",
       "  'из',\n",
       "  'ему',\n",
       "  'теперь',\n",
       "  'когда',\n",
       "  'даже',\n",
       "  'ну',\n",
       "  'вдруг',\n",
       "  'ли',\n",
       "  'если',\n",
       "  'уже',\n",
       "  'или',\n",
       "  'ни',\n",
       "  'быть',\n",
       "  'был',\n",
       "  'него',\n",
       "  'до',\n",
       "  'вас',\n",
       "  'нибудь',\n",
       "  'опять',\n",
       "  'уж',\n",
       "  'вам',\n",
       "  'ведь',\n",
       "  'там',\n",
       "  'потом',\n",
       "  'себя',\n",
       "  'ничего',\n",
       "  'ей',\n",
       "  'может',\n",
       "  'они',\n",
       "  'тут',\n",
       "  'где',\n",
       "  'есть',\n",
       "  'надо',\n",
       "  'ней',\n",
       "  'для',\n",
       "  'мы',\n",
       "  'тебя',\n",
       "  'их',\n",
       "  'чем',\n",
       "  'была',\n",
       "  'сам',\n",
       "  'чтоб',\n",
       "  'без',\n",
       "  'будто',\n",
       "  'чего',\n",
       "  'раз',\n",
       "  'тоже',\n",
       "  'себе',\n",
       "  'под',\n",
       "  'будет',\n",
       "  'ж',\n",
       "  'тогда',\n",
       "  'кто',\n",
       "  'этот',\n",
       "  'того',\n",
       "  'потому',\n",
       "  'этого',\n",
       "  'какой',\n",
       "  'совсем',\n",
       "  'ним',\n",
       "  'здесь',\n",
       "  'этом',\n",
       "  'один',\n",
       "  'почти',\n",
       "  'мой',\n",
       "  'тем',\n",
       "  'чтобы',\n",
       "  'нее',\n",
       "  'сейчас',\n",
       "  'были',\n",
       "  'куда',\n",
       "  'зачем',\n",
       "  'всех',\n",
       "  'никогда',\n",
       "  'можно',\n",
       "  'при',\n",
       "  'наконец',\n",
       "  'два',\n",
       "  'об',\n",
       "  'другой',\n",
       "  'хоть',\n",
       "  'после',\n",
       "  'над',\n",
       "  'больше',\n",
       "  'тот',\n",
       "  'через',\n",
       "  'эти',\n",
       "  'нас',\n",
       "  'про',\n",
       "  'всего',\n",
       "  'них',\n",
       "  'какая',\n",
       "  'много',\n",
       "  'разве',\n",
       "  'три',\n",
       "  'эту',\n",
       "  'моя',\n",
       "  'впрочем',\n",
       "  'хорошо',\n",
       "  'свою',\n",
       "  'этой',\n",
       "  'перед',\n",
       "  'иногда',\n",
       "  'лучше',\n",
       "  'чуть',\n",
       "  'том',\n",
       "  'нельзя',\n",
       "  'такой',\n",
       "  'им',\n",
       "  'более',\n",
       "  'всегда',\n",
       "  'конечно',\n",
       "  'всю',\n",
       "  'между']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 76.39223651587547,\n",
       " 'max_df': 0.9690781859494049,\n",
       " 'min_df': 1.2200877751358113e-05,\n",
       " 'ngram_range': (1, 1),\n",
       " 'stemming': False,\n",
       " 'stop_words': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_obscenity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_normal = {'C': 73.52580652715072,\n",
    "#                'max_df': 0.9696315615375243,\n",
    "#                'min_df': 2.1701497893422727e-05,\n",
    "#                'ngram_range': (1, 2),\n",
    "#                'stemming': False,\n",
    "#                'stop_words': None\n",
    "#               }\n",
    "# Average precision score train: 0.9996649882629408 from another notebook\n",
    "# Average precision score test: 0.9924950275198423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def cook_algo(XY, label, params):\n",
    "    space_trans = {key: value for key, value in params.items() if (key != 'C') and (key != 'stemming')}\n",
    "    \n",
    "    trans = TfidfVectorizer(**space_trans)\n",
    "    clf = LogisticRegression(class_weight = 'balanced', C = params['C'])\n",
    "    \n",
    "    X = XY.text_stemmed if params['stemming'] else XY.text\n",
    "    y = XY[label]\n",
    "        \n",
    "    pipe = Pipeline([('trans', TfidfVectorizer(**space_trans)), \n",
    "                     ('clf', LogisticRegression(C = params['C']))])\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    print(f'Average precision score: {average_precision_score(y_score = pipe.predict_proba(X)[:, 1], y_true = y)}')\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(XY, label, params, pipeline):\n",
    "    X = XY.text_stemmed if params['stemming'] else XY.text\n",
    "    y = XY[label]\n",
    "    \n",
    "    y_pred = pipeline.predict_proba(X)[:, 1]\n",
    "    print(f'Average precision score: {average_precision_score(y_score = y_pred, y_true = y)}')\n",
    "    \n",
    "    return y_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9962720089665845\n",
      "Average precision score: 0.9286916279788466\n",
      "Average precision score: 0.8754930896826478\n",
      "Average precision score: 0.9933882121816242\n"
     ]
    }
   ],
   "source": [
    "pipe_normal = cook_algo(XY_train, 'normal', best_normal)\n",
    "pipe_insult = cook_algo(XY_train, 'insult', best_insult)\n",
    "pipe_threat = cook_algo(XY_train, 'threat', best_threat)\n",
    "pipe_obscenity = cook_algo(XY_train, 'obscenity', best_obscenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9962720089665845\n",
      "Average precision score: 0.9909018049370828\n"
     ]
    }
   ],
   "source": [
    "preds_normal_train = my_predict(XY_train, 'normal', best_normal, pipe_normal)\n",
    "preds_normal_test = my_predict(XY_test, 'normal', best_normal, pipe_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9286916279788466\n",
      "Average precision score: 0.8672494906009367\n"
     ]
    }
   ],
   "source": [
    "preds_insult_train = my_predict(XY_train, 'insult', best_insult, pipe_insult)\n",
    "preds_insult_test = my_predict(XY_test, 'insult', best_insult, pipe_insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.8754930896826478\n",
      "Average precision score: 0.7869322209839801\n"
     ]
    }
   ],
   "source": [
    "preds_threat_train = my_predict(XY_train, 'threat', best_threat, pipe_threat)\n",
    "preds_threat_test = my_predict(XY_test, 'threat', best_threat, pipe_threat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.9933882121816242\n",
      "Average precision score: 0.7647738738449493\n"
     ]
    }
   ],
   "source": [
    "preds_obscenity_train = my_predict(XY_train, 'obscenity', best_obscenity, pipe_obscenity)\n",
    "preds_obscenity_test = my_predict(XY_test, 'obscenity', best_obscenity, pipe_obscenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>какая прелесть!!!😍</td>\n",
       "      <td>какая прелесть😍</td>\n",
       "      <td>какой прелесть😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>каал какой не с кровью?</td>\n",
       "      <td>каа какой не с кров</td>\n",
       "      <td>каала какой не с кровь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>гнойные пидоры аллы они</td>\n",
       "      <td>гнойн пидор алл они</td>\n",
       "      <td>гнойный пидор алла они</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     text         text_stemmed  \\\n",
       "0  167315       какая прелесть!!!😍      какая прелесть😍   \n",
       "1  224546  каал какой не с кровью?  каа какой не с кров   \n",
       "2  241309  гнойные пидоры аллы они  гнойн пидор алл они   \n",
       "\n",
       "          text_lemmatised  \n",
       "0         какой прелесть😍  \n",
       "1  каала какой не с кровь  \n",
       "2  гнойный пидор алла они  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)\n",
    "X_final_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.hstack([predict_with_aka_bagging(algs_final[label], X_final_test, label).reshape(-1, 1)\n",
    "#                          for label in list(algs_final.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_predictions = pd.concat([pd.DataFrame(X_final_test.id.values, columns = ['id']),\n",
    "#                                pd.DataFrame(predictions, columns = list(algs_final.keys()))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = final_predictions.loc[:, ['id', 'normal', 'insult', 'obscenity', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('result', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
