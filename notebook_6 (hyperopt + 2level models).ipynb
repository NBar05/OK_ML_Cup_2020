{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "srmZrir30OL5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "ZzKSezAp0OMJ",
    "outputId": "93852034-0e37-4273-c11d-2de43a378543",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>дворника надо тоже уничтожить!</td>\n",
       "      <td>дворник надо тоже уничтож</td>\n",
       "      <td>дворник надо тоже уничтожить</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>моя старшая неделю шипела, не принимала подкид...</td>\n",
       "      <td>моя старш недел шипел не принима подкидыш кото...</td>\n",
       "      <td>мой старший неделя шипеть не принимать подкиды...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>полностью с вами согласна!</td>\n",
       "      <td>полност с вам согласн</td>\n",
       "      <td>полностью с вы согласный</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     дворника надо тоже уничтожить!   \n",
       "1   6812  моя старшая неделю шипела, не принимала подкид...   \n",
       "2   6256                         полностью с вами согласна!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          дворник надо тоже уничтож   \n",
       "1  моя старш недел шипел не принима подкидыш кото...   \n",
       "2                              полност с вам согласн   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       дворник надо тоже уничтожить       0       1       0   \n",
       "1  мой старший неделя шипеть не принимать подкиды...       1       0       0   \n",
       "2                           полностью с вы согласный       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KCI2T-A0OMT",
    "outputId": "f130e329-2974-4ac2-f735-629b64c0cbdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 10), (18547, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY['exclamation_num'] = XY.text.str.count('!')\n",
    "XY['question_num'] = XY.text.str.count('\\?')\n",
    "\n",
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GTRux1Go0OMg"
   },
   "outputs": [],
   "source": [
    "def hyperopt_tdidf_logit_label(label):\n",
    "    \n",
    "    X = XY_train.text\n",
    "    y = XY_train[label]\n",
    "    \n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def hyperopt_tdidf_logit(params):\n",
    "        \n",
    "        pipe = Pipeline([('trans', TfidfVectorizer(min_df = 2)), ('clf', LogisticRegression(**params))])\n",
    "\n",
    "        score = cross_val_score(estimator = pipe, X = X, y = y,\n",
    "                                cv = StratifiedKFold(n_splits = 7), scoring = 'average_precision')\n",
    "\n",
    "        score_mean = score.mean()\n",
    "\n",
    "        return -score_mean\n",
    "\n",
    "    space_tfidf_logit = {'C': hp.uniform('C', 1, 25)}\n",
    "    \n",
    "    best = fmin(fn = hyperopt_tdidf_logit, space = space_tfidf_logit, algo = tpe.suggest, max_evals = 50)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    pipe = Pipeline([('trans', TfidfVectorizer(min_df = 2)), ('clf', LogisticRegression(**best))])\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    print(average_precision_score(y_score = pipe.predict_proba(X)[:, 1], y_true = y))\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlRwm1Vh0OMm",
    "outputId": "ef24e8fe-53db-46c3-84ec-c97061d710d4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# algs_1 = dict()\n",
    "# for label in ['normal', 'insult', 'obscenity', 'threat']:\n",
    "#     print('----------------------------------------------------------------------------------------------------')\n",
    "#     print(label)\n",
    "#     print('----------------------------------------------------------------------------------------------------')\n",
    "#     print()\n",
    "#     algs_1[label] = hyperopt_tdidf_logit_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJRsdRRMOQnZ",
    "outputId": "04af64bf-64b6-4feb-c2ad-1db27fae4e36",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# algs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.36 s, sys: 70.9 ms, total: 3.43 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# text feature extraction - level 1\n",
    "trans_1_2_11 = TfidfVectorizer(min_df = 2)\n",
    "text_train_1 = trans_1_2_11.fit_transform(XY_train.text)\n",
    "text_test_1 = trans_1_2_11.transform(XY_test.text)\n",
    "\n",
    "# classifier - level 1\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "# clf_1_normal = LogisticRegression(C = 5.3).fit(text_train_1, XY_train['normal'])\n",
    "# clf_1_insult = LogisticRegression(C = 12).fit(text_train_1, XY_train['insult'])\n",
    "# clf_1_threat = LogisticRegression(C = 10.6).fit(text_train_1, XY_train['threat'])\n",
    "# clf_1_obscenity = LogisticRegression(C = 21.8).fit(text_train_1, XY_train['obscenity'])\n",
    "\n",
    "# pred_train_normal_1 = clf_1_normal.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "# pred_train_insult_1 = clf_1_insult.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "# pred_train_threat_1 = clf_1_threat.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "# pred_train_obscenity_1 = clf_1_obscenity.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "\n",
    "# pred_test_normal_1 = clf_1_normal.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "# pred_test_insult_1 = clf_1_insult.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "# pred_test_threat_1 = clf_1_threat.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "# pred_test_obscenity_1 = clf_1_obscenity.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "\n",
    "# text feature extraction - level 2\n",
    "stopWords = stopwords.words('russian') + ['это', 'всё', 'весь', 'ещё', 'человек', 'твой', 'который', 'идти', 'суд',\n",
    "                                          'свой', 'рука', 'нужно', 'ребёнок', 'её', 'жить', 'просто', 'наш', 'ваш',\n",
    "                                          'россия', 'страна', 'мочь', 'народ', 'путин', 'путинский', 'россия',\n",
    "                                          'нога', 'жена', 'место', 'мужик', 'далёкий', 'мама', 'день', 'сказать',\n",
    "                                          'каждый', 'пусть', 'делать', 'любить', 'знать', 'хороший', 'большой',\n",
    "                                          'земля', 'слово', 'найти', 'стенка', 'вместе', 'взять', 'самый', 'яйцо',\n",
    "                                          'сколько', 'смотреть', 'сделать', 'голова', 'говорить', 'вообще', 'год',\n",
    "                                          'деньга', 'продажный', 'писать', 'работать', 'думать', 'жизнь', 'мозг',\n",
    "                                          'русский', 'сразу', 'мало', 'площадь', 'собака', 'ести', 'рот', 'хотеть',\n",
    "                                          'давать', 'мать', 'выести', 'сидеть', 'пойти', 'дать', 'давно', 'сажать',\n",
    "                                          'полный', 'пора', 'стать', 'должный', 'стать', 'время', 'пока', 'власть',\n",
    "                                          'никто', 'привязать', 'бог', 'скоро', 'кормить' 'враг', 'шея', 'башка', \n",
    "                                          'баба', 'муж', 'показать', 'украина', 'старый', 'родитель', 'посадить',\n",
    "                                          'видеть', 'враг', 'супер', 'женщина', 'стоить', 'классный', 'первый', \n",
    "                                          'начать', 'валить', 'предатель', 'fr', 'fr fr', 'следствие', 'придурок', \n",
    "                                          'привет', 'нужный', 'решить', '8oi', 'че', 'кормить', 'друг', 'дурак', \n",
    "                                          'посмотреть', 'дело', 'оба', 'почему', 'мир', 'уметь','ответить', 'семья',\n",
    "                                          'язык', 'видно', 'бояться', 'давить', 'всякий', 'хозяин', 'красивый', \n",
    "                                          'глаз', 'девочка', 'поставить', 'маленький', 'хотеться', 'остальной',\n",
    "                                          'очень', 'сталин', 'закон', 'наверное', 'прийти', 'иметь', 'класс', 'тя',\n",
    "                                          'ночь', 'ждать', 'также']\n",
    "# tf = TfidfVectorizer(min_df = 0.01, ngram_range = (1, 2), stop_words = stopWords)\n",
    "tf_insult = CountVectorizer(max_features = 50, ngram_range = (1, 2), \n",
    "                            stop_words = stopWords).fit(XY_train.loc[XY_train.insult == 1, 'text_lemmatised'])\n",
    "tf_threat = CountVectorizer(max_features = 75, ngram_range = (1, 2), \n",
    "                            stop_words = stopWords).fit(XY_train.loc[XY_train.threat == 1, 'text_lemmatised'])\n",
    "tf_obscenity = CountVectorizer(max_features = 75, ngram_range = (1, 2), \n",
    "                               stop_words = stopWords).fit(XY_train.loc[XY_train.obscenity == 1, 'text_lemmatised'])\n",
    "\n",
    "# text_train_insult_2 = (tf_insult.transform(XY_train.text_lemmatised).toarray() > 0).astype('int')\n",
    "# text_test_insult_2 = (tf_insult.transform(XY_test.text_lemmatised).toarray() > 0).astype('int')\n",
    "\n",
    "# text_train_threat_2 = (tf_threat.transform(XY_train.text_lemmatised).toarray() > 0).astype('int')\n",
    "# text_test_threat_2 = (tf_threat.transform(XY_test.text_lemmatised).toarray() > 0).astype('int')\n",
    "\n",
    "# text_train_obscenity_2 = (tf_obscenity.transform(XY_train.text_lemmatised).toarray() > 0).astype('int')\n",
    "# text_test_obscenity_2 = (tf_obscenity.transform(XY_test.text_lemmatised).toarray() > 0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['быдло',\n",
       " 'дрочить',\n",
       " 'кончить',\n",
       " 'минуть',\n",
       " 'отрезать',\n",
       " 'ебал',\n",
       " 'пиздец',\n",
       " 'вдуть',\n",
       " 'полизать',\n",
       " 'соснуть',\n",
       " 'повесить',\n",
       " 'сын',\n",
       " 'брать',\n",
       " 'утопить',\n",
       " 'пизда',\n",
       " 'сперма',\n",
       " 'сестра',\n",
       " 'козёл',\n",
       " 'пидорас',\n",
       " 'набить',\n",
       " 'говно',\n",
       " 'закопать',\n",
       " 'хохол',\n",
       " 'вор',\n",
       " 'дура',\n",
       " 'ублюдок',\n",
       " 'казнить',\n",
       " 'выебал',\n",
       " 'лизать',\n",
       " 'засадить',\n",
       " 'чмо',\n",
       " 'растрела',\n",
       " 'задница',\n",
       " 'прилюдно',\n",
       " 'гнида',\n",
       " 'сука',\n",
       " 'растрелять',\n",
       " 'насосать',\n",
       " 'сосать сосать',\n",
       " 'пиздить',\n",
       " 'проклятый',\n",
       " 'бить',\n",
       " 'отстреливать',\n",
       " 'ебу',\n",
       " 'убивать',\n",
       " 'конченый',\n",
       " 'животное',\n",
       " 'секс',\n",
       " 'блядь',\n",
       " 'написать',\n",
       " 'шлюха',\n",
       " 'очко',\n",
       " 'фашист',\n",
       " 'ебета',\n",
       " 'отрубить',\n",
       " 'пососать',\n",
       " 'сдохнуть',\n",
       " 'стрелять',\n",
       " 'уничтожать',\n",
       " 'рак',\n",
       " 'сжечь',\n",
       " 'гад',\n",
       " 'сиська',\n",
       " 'ёбаный',\n",
       " 'прибить',\n",
       " 'трахат',\n",
       " 'дебил',\n",
       " 'шалавый',\n",
       " 'растреливать',\n",
       " 'негр',\n",
       " 'отсасывать',\n",
       " 'оторвать',\n",
       " 'хер',\n",
       " 'урод',\n",
       " 'пидарас',\n",
       " 'кастрировать',\n",
       " 'поп',\n",
       " 'пристрелить',\n",
       " 'падло',\n",
       " 'трахнуть',\n",
       " 'засунуть',\n",
       " 'морда',\n",
       " 'выебать',\n",
       " 'жопа',\n",
       " 'срак',\n",
       " 'живьём',\n",
       " 'хуйня',\n",
       " 'понять',\n",
       " 'мочить',\n",
       " 'расстрелять',\n",
       " 'ад',\n",
       " 'расстрел',\n",
       " 'ебут',\n",
       " 'уничтожить',\n",
       " 'подвесить',\n",
       " 'гандон',\n",
       " 'мразь',\n",
       " 'подрочить',\n",
       " 'расстреливать',\n",
       " 'бля',\n",
       " 'повадно',\n",
       " 'отлизать',\n",
       " 'ебануть',\n",
       " 'вешать',\n",
       " 'хуй сосать',\n",
       " 'гореть',\n",
       " 'кол',\n",
       " 'пидор',\n",
       " 'сволочь',\n",
       " 'идиот',\n",
       " 'остаться',\n",
       " 'ебать',\n",
       " 'петух',\n",
       " 'пися',\n",
       " 'ротик',\n",
       " 'попка',\n",
       " 'хрен',\n",
       " 'сучка',\n",
       " 'наказать',\n",
       " 'хуй',\n",
       " 'долбоеб',\n",
       " 'тюрьма',\n",
       " 'дырка',\n",
       " 'поймать',\n",
       " 'сосать хуй',\n",
       " 'точно',\n",
       " 'нахуй',\n",
       " 'тупой',\n",
       " 'вонючий',\n",
       " 'трахаться',\n",
       " 'трахать',\n",
       " 'тварь',\n",
       " 'рожа',\n",
       " 'девушка',\n",
       " 'член',\n",
       " 'гореть ад',\n",
       " 'отсосать',\n",
       " 'долбоести',\n",
       " 'сосать',\n",
       " 'пидар',\n",
       " 'убить',\n",
       " 'смерть']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(tf_insult.vocabulary_) | set(tf_threat.vocabulary_) | set(tf_obscenity.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:20<00:00, 24.43trial/s, best loss: -0.9909100993058516]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def mini_hyperopt(param):\n",
    "    y_pred = np.array(pred_train_normal_1 >= param['threshold'], dtype = 'int')\n",
    "    return -f1_score(y_pred = y_pred, y_true = XY_train['normal'])\n",
    "    \n",
    "space_thres = {'threshold': hp.uniform('threshold', 0, 1)}\n",
    "    \n",
    "best_mini = fmin(fn = mini_hyperopt, space = space_thres, algo = tpe.suggest, max_evals = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_normal_bool_1 = np.array(pred_train_normal_1 >= round(best_mini['threshold'], 3), dtype = 'int')\n",
    "pred_test_normal_bool_1 = np.array(pred_test_normal_1 >= round(best_mini['threshold'], 3), dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2_insult = np.concatenate([pred_train_insult_1, pred_train_normal_bool_1, text_train_insult_2], \n",
    "                                axis = 1)\n",
    "train_2_threat = np.concatenate([pred_train_threat_1, pred_train_normal_bool_1, text_train_threat_2], \n",
    "                                axis = 1)\n",
    "train_2_obscenity = np.concatenate([pred_train_obscenity_1, pred_train_normal_bool_1, text_train_obscenity_2], \n",
    "                                   axis = 1)\n",
    "\n",
    "test_2_insult = np.concatenate([pred_test_insult_1, pred_test_normal_bool_1, text_test_insult_2], \n",
    "                               axis = 1)\n",
    "test_2_threat = np.concatenate([pred_test_threat_1, pred_test_normal_bool_1, text_test_threat_2], \n",
    "                               axis = 1)\n",
    "test_2_obscenity = np.concatenate([pred_test_obscenity_1, pred_test_normal_bool_1, text_test_obscenity_2], \n",
    "                                  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:37<00:00,  1.15trial/s, best loss: -0.9153770907605178]\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_2(params):\n",
    "    \n",
    "    lg = LogisticRegression(**params).fit(train_2_insult, XY_train['insult'])\n",
    "    score = average_precision_score(y_score = lg.predict_proba(test_2_insult)[:, 1], y_true = XY_test['insult'])\n",
    "    \n",
    "    return -score\n",
    "    \n",
    "best_insult_C_2 = fmin(fn = hyperopt_2, space = {'C': hp.uniform('C', 0.01, 10),\n",
    "                                                 'class_weight': hp.choice('class_weight', [None, 'balanced'])},\n",
    "                       algo = tpe.suggest, max_evals = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.03578957898023842, 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_insult_C_2['class_weight'] = [None, 'balanced'][best_insult_C_2['class_weight']]\n",
    "best_insult_C_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(**best_insult_C_2).fit(train_2_insult, XY_train['insult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9153770907605178"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_score = lg.predict_proba(test_2_insult)[:, 1], y_true = XY_test['insult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:15<00:00,  1.28trial/s, best loss: -0.8853170353601449]\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_2(params):\n",
    "    \n",
    "    lg = LogisticRegression(**params).fit(train_2_threat, XY_train['threat'])\n",
    "    score = average_precision_score(y_score = lg.predict_proba(test_2_threat)[:, 1], y_true = XY_test['threat'])\n",
    "    \n",
    "    return -score\n",
    "    \n",
    "best_threat_C_2 = fmin(fn = hyperopt_2, space = {'C': hp.uniform('C', 0.01, 10),\n",
    "                                                 'class_weight': hp.choice('class_weight', [None, 'balanced'])},\n",
    "                       algo = tpe.suggest, max_evals = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.02527516977232648, 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threat_C_2['class_weight'] = [None, 'balanced'][best_threat_C_2['class_weight']]\n",
    "best_threat_C_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(**best_threat_C_2).fit(train_2_threat, XY_train['threat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8853170353601449"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_score = lg.predict_proba(test_2_threat)[:, 1], y_true = XY_test['threat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:12<00:00,  1.89trial/s, best loss: -0.7729510611264273]\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_2(params):\n",
    "    \n",
    "    lg = LogisticRegression(**params).fit(train_2_obscenity, XY_train['obscenity'])\n",
    "    score = average_precision_score(y_score = lg.predict_proba(test_2_obscenity)[:, 1], y_true = XY_test['obscenity'])\n",
    "    \n",
    "    return -score\n",
    "    \n",
    "best_obscenity_C_2 = fmin(fn = hyperopt_2, space = {'C': hp.uniform('C', 0.01, 10),\n",
    "                                                    'class_weight': hp.choice('class_weight', [None, 'balanced'])},\n",
    "                          algo = tpe.suggest, max_evals = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.2923206108631109, 'class_weight': None}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_obscenity_C_2['class_weight'] = [None, 'balanced'][best_obscenity_C_2['class_weight']]\n",
    "best_obscenity_C_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(**best_obscenity_C_2).fit(train_2_obscenity, XY_train['obscenity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729510611264273"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_score = lg.predict_proba(test_2_obscenity)[:, 1], y_true = XY_test['obscenity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "id": "UAexmbXV0ONc",
    "outputId": "8617ec54-4bec-4d7a-ddd2-589e23a22347",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>какая прелесть!!!😍</td>\n",
       "      <td>какая прелесть😍</td>\n",
       "      <td>какой прелесть😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>каал какой не с кровью?</td>\n",
       "      <td>каа какой не с кров</td>\n",
       "      <td>каала какой не с кровь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>гнойные пидоры аллы они</td>\n",
       "      <td>гнойн пидор алл они</td>\n",
       "      <td>гнойный пидор алла они</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     text         text_stemmed  \\\n",
       "0  167315       какая прелесть!!!😍      какая прелесть😍   \n",
       "1  224546  каал какой не с кровью?  каа какой не с кров   \n",
       "2  241309  гнойные пидоры аллы они  гнойн пидор алл они   \n",
       "\n",
       "          text_lemmatised  \n",
       "0         какой прелесть😍  \n",
       "1  каала какой не с кровь  \n",
       "2  гнойный пидор алла они  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)\n",
    "X_final_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "id": "HuiwWJcg0ONb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:29<00:00, 17.08trial/s, best loss: -0.9914620782152145]\n"
     ]
    }
   ],
   "source": [
    "# text feature extraction - level 1\n",
    "trans_1_2_11 = TfidfVectorizer(min_df = 2)\n",
    "text_train_1 = trans_1_2_11.fit_transform(XY.text)\n",
    "text_test_1 = trans_1_2_11.transform(X_final_test.text)\n",
    "\n",
    "# classifier - level 1\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "clf_1_normal = LogisticRegression(C = 5.3).fit(text_train_1, XY['normal'])\n",
    "clf_1_insult = LogisticRegression(C = 12).fit(text_train_1, XY['insult'])\n",
    "clf_1_threat = LogisticRegression(C = 10.6).fit(text_train_1, XY['threat'])\n",
    "clf_1_obscenity = LogisticRegression(C = 21.8).fit(text_train_1, XY['obscenity'])\n",
    "\n",
    "pred_train_normal_1 = clf_1_normal.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "pred_train_insult_1 = clf_1_insult.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "pred_train_threat_1 = clf_1_threat.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "pred_train_obscenity_1 = clf_1_obscenity.predict_proba(text_train_1)[:, 1].reshape(-1, 1)\n",
    "\n",
    "pred_test_normal_1 = clf_1_normal.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "pred_test_insult_1 = clf_1_insult.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "pred_test_threat_1 = clf_1_threat.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "pred_test_obscenity_1 = clf_1_obscenity.predict_proba(text_test_1)[:, 1].reshape(-1, 1)\n",
    "\n",
    "# text feature extraction - level 2\n",
    "stopWords = stopwords.words('russian') + ['это', 'всё', 'весь', 'ещё', 'человек', 'твой', 'который', 'идти', 'суд',\n",
    "                                          'свой', 'рука', 'нужно', 'ребёнок', 'её', 'жить', 'просто', 'наш', 'ваш',\n",
    "                                          'россия', 'страна', 'мочь', 'народ', 'путин', 'путинский', 'россия',\n",
    "                                          'нога', 'жена', 'место', 'мужик', 'далёкий', 'мама', 'день', 'сказать',\n",
    "                                          'каждый', 'пусть', 'делать', 'любить', 'знать', 'хороший', 'большой',\n",
    "                                          'земля', 'слово', 'найти', 'стенка', 'вместе', 'взять', 'самый', 'яйцо',\n",
    "                                          'сколько', 'смотреть', 'сделать', 'голова', 'говорить', 'вообще', 'год',\n",
    "                                          'деньга', 'продажный', 'писать', 'работать', 'думать', 'жизнь', 'мозг',\n",
    "                                          'русский', 'сразу', 'мало', 'площадь', 'собака', 'ести', 'рот', 'хотеть',\n",
    "                                          'давать', 'мать', 'выести', 'сидеть', 'пойти', 'дать', 'давно', 'сажать',\n",
    "                                          'полный', 'пора', 'стать', 'должный', 'стать', 'время', 'пока', 'власть',\n",
    "                                          'никто', 'привязать', 'бог', 'скоро', 'кормить' 'враг', 'шея', 'башка', \n",
    "                                          'баба', 'муж', 'показать', 'украина', 'старый', 'родитель', 'посадить',\n",
    "                                          'видеть', 'враг', 'супер', 'женщина']\n",
    "\n",
    "tf_insult = CountVectorizer(max_features = 25, ngram_range = (1, 2), \n",
    "                            stop_words = stopWords).fit(XY.loc[XY.insult == 1, 'text_lemmatised'])\n",
    "tf_threat = CountVectorizer(max_features = 25, ngram_range = (1, 2), \n",
    "                            stop_words = stopWords).fit(XY.loc[XY.threat == 1, 'text_lemmatised'])\n",
    "tf_obscenity = CountVectorizer(max_features = 25, ngram_range = (1, 2), \n",
    "                               stop_words = stopWords).fit(XY.loc[XY.obscenity == 1, 'text_lemmatised'])\n",
    "\n",
    "text_train_insult_2 = (tf_insult.transform(XY.text_lemmatised).toarray() > 0).astype('int')\n",
    "text_test_insult_2 = (tf_insult.transform(X_final_test.text_lemmatised).toarray() > 0).astype('int')\n",
    "\n",
    "text_train_threat_2 = (tf_threat.transform(XY.text_lemmatised).toarray() > 0).astype('int')\n",
    "text_test_threat_2 = (tf_threat.transform(X_final_test.text_lemmatised).toarray() > 0).astype('int')\n",
    "\n",
    "text_train_obscenity_2 = (tf_obscenity.transform(XY.text_lemmatised).toarray() > 0).astype('int')\n",
    "text_test_obscenity_2 = (tf_obscenity.transform(X_final_test.text_lemmatised).toarray() > 0).astype('int')\n",
    "\n",
    "def mini_hyperopt(param):\n",
    "    y_pred = np.array(pred_train_normal_1 >= param['threshold'], dtype = 'int')\n",
    "    return -f1_score(y_pred = y_pred, y_true = XY['normal'])\n",
    "    \n",
    "space_thres = {'threshold': hp.uniform('threshold', 0, 1)}\n",
    "    \n",
    "best_mini = fmin(fn = mini_hyperopt, space = space_thres, algo = tpe.suggest, max_evals = 500)\n",
    "\n",
    "\n",
    "pred_train_normal_bool_1 = np.array(pred_train_normal_1 >= round(best_mini['threshold'], 3), dtype = 'int')\n",
    "pred_test_normal_bool_1 = np.array(pred_test_normal_1 >= round(best_mini['threshold'], 3), dtype = 'int')\n",
    "\n",
    "\n",
    "train_2_insult = np.concatenate([pred_train_insult_1, pred_train_normal_bool_1, text_train_insult_2], \n",
    "                                axis = 1)\n",
    "train_2_threat = np.concatenate([pred_train_threat_1, pred_train_normal_bool_1, text_train_threat_2], \n",
    "                                axis = 1)\n",
    "train_2_obscenity = np.concatenate([pred_train_obscenity_1, pred_train_normal_bool_1, text_train_obscenity_2], \n",
    "                                   axis = 1)\n",
    "\n",
    "test_2_insult = np.concatenate([pred_test_insult_1, pred_test_normal_bool_1, text_test_insult_2], \n",
    "                               axis = 1)\n",
    "test_2_threat = np.concatenate([pred_test_threat_1, pred_test_normal_bool_1, text_test_threat_2], \n",
    "                               axis = 1)\n",
    "test_2_obscenity = np.concatenate([pred_test_obscenity_1, pred_test_normal_bool_1, text_test_obscenity_2], \n",
    "                                  axis = 1)\n",
    "\n",
    "lg_insult = LogisticRegression(**best_insult_C_2).fit(train_2_insult, XY['insult'])\n",
    "lg_threat = LogisticRegression(**best_threat_C_2).fit(train_2_threat, XY['threat'])\n",
    "lg_obscenity = LogisticRegression(**best_obscenity_C_2).fit(train_2_obscenity, XY['obscenity'])\n",
    "\n",
    "pred_test_insult_2 = lg_insult.predict_proba(test_2_insult)[:, 1].reshape(-1, 1)\n",
    "pred_test_threat_2 = lg_threat.predict_proba(test_2_threat)[:, 1].reshape(-1, 1)\n",
    "pred_test_obscenity_2 = lg_obscenity.predict_proba(test_2_obscenity)[:, 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "id": "TWbe9_sZ0ONi"
   },
   "outputs": [],
   "source": [
    "predictions = np.hstack([pred_test_normal_1, pred_test_insult_2, pred_test_threat_2, pred_test_obscenity_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['normal', 'insult', 'threat', 'obscenity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "dpk6iVIX0ONj"
   },
   "outputs": [],
   "source": [
    "final_predictions = pd.concat([pd.DataFrame(X_final_test.id.values, columns = ['id']),\n",
    "                               pd.DataFrame(predictions, columns = labels)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>normal</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>0.926286</td>\n",
       "      <td>0.038597</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.105649</td>\n",
       "      <td>0.002020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31170</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173358</td>\n",
       "      <td>0.957654</td>\n",
       "      <td>0.033564</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99510</th>\n",
       "      <td>192320</td>\n",
       "      <td>0.356521</td>\n",
       "      <td>0.333875</td>\n",
       "      <td>0.085667</td>\n",
       "      <td>0.030779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99511</th>\n",
       "      <td>6646</td>\n",
       "      <td>0.099780</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.103001</td>\n",
       "      <td>0.002165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99512</th>\n",
       "      <td>215218</td>\n",
       "      <td>0.874958</td>\n",
       "      <td>0.152845</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99513</th>\n",
       "      <td>139806</td>\n",
       "      <td>0.773577</td>\n",
       "      <td>0.200878</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99514</th>\n",
       "      <td>99052</td>\n",
       "      <td>0.979588</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99515 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    normal    insult    threat  obscenity\n",
       "0      167315  0.998016  0.023758  0.008704   0.000562\n",
       "1      224546  0.926286  0.038597  0.012242   0.000585\n",
       "2      241309  0.017610  0.999779  0.105649   0.002020\n",
       "3       31170  0.000691  0.999798  0.098300   0.003319\n",
       "4      173358  0.957654  0.033564  0.008842   0.000577\n",
       "...       ...       ...       ...       ...        ...\n",
       "99510  192320  0.356521  0.333875  0.085667   0.030779\n",
       "99511    6646  0.099780  0.999746  0.103001   0.002165\n",
       "99512  215218  0.874958  0.152845  0.008986   0.000564\n",
       "99513  139806  0.773577  0.200878  0.009405   0.000571\n",
       "99514   99052  0.979588  0.025177  0.009258   0.000599\n",
       "\n",
       "[99515 rows x 5 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "id": "UbahSrcW0ONk"
   },
   "outputs": [],
   "source": [
    "result = final_predictions.loc[:, ['id', 'normal', 'insult', 'obscenity', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "id": "jfiODFw10ONm"
   },
   "outputs": [],
   "source": [
    "result.to_csv('result', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_6 (simple hyperopt).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
