{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>дворника надо тоже уничтожить!</td>\n",
       "      <td>дворник надо тоже уничтож</td>\n",
       "      <td>дворник надо тоже уничтожить</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>моя старшая неделю шипела, не принимала подкид...</td>\n",
       "      <td>моя старш недел шипел не принима подкидыш кото...</td>\n",
       "      <td>мой старший неделя шипеть не принимать подкиды...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>полностью с вами согласна!</td>\n",
       "      <td>полност с вам согласн</td>\n",
       "      <td>полностью с вы согласный</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     дворника надо тоже уничтожить!   \n",
       "1   6812  моя старшая неделю шипела, не принимала подкид...   \n",
       "2   6256                         полностью с вами согласна!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          дворник надо тоже уничтож   \n",
       "1  моя старш недел шипел не принима подкидыш кото...   \n",
       "2                              полност с вам согласн   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       дворник надо тоже уничтожить       0       1       0   \n",
       "1  мой старший неделя шипеть не принимать подкиды...       1       0       0   \n",
       "2                           полностью с вы согласный       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 8), (18547, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36330, 21061, 21325)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = TfidfVectorizer(min_df = 3)\n",
    "trans_stemmed = TfidfVectorizer(min_df = 3)\n",
    "trans_lemmatised = TfidfVectorizer(min_df = 3)\n",
    "X_train = trans.fit_transform(XY_train.text)\n",
    "X_train_stemmed = trans_stemmed.fit_transform(XY_train.text_stemmed)\n",
    "X_train_lemmatised = trans_lemmatised.fit_transform(XY_train.text_lemmatised)\n",
    "X_test = trans.transform(XY_test.text)\n",
    "X_test_stemmed = trans_stemmed.transform(XY_test.text_stemmed)\n",
    "X_test_lemmatised = trans_lemmatised.transform(XY_test.text_lemmatised)\n",
    "\n",
    "len(trans.vocabulary_), len(trans_stemmed.vocabulary_), len(trans_lemmatised.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "814/814 [==============================] - 43s 53ms/step - loss: 0.4326 - auc_8: 0.9722\n",
      "Epoch 2/5\n",
      "814/814 [==============================] - 43s 53ms/step - loss: 0.4077 - auc_8: 0.9777\n",
      "Epoch 3/5\n",
      "814/814 [==============================] - 43s 53ms/step - loss: 0.4401 - auc_8: 0.9769\n",
      "Epoch 4/5\n",
      "814/814 [==============================] - 44s 54ms/step - loss: 0.4565 - auc_8: 0.9767\n",
      "Epoch 5/5\n",
      "814/814 [==============================] - 44s 54ms/step - loss: 0.4835 - auc_8: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd293dd2b20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(800, activation = 'relu', input_dim = len(trans_lemmatised.vocabulary_)))\n",
    "model.add(keras.layers.Dropout(0.8))\n",
    "model.add(keras.layers.Dense(4, activation = 'softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[keras.metrics.AUC()])\n",
    "model.fit(X_train_lemmatised.astype('float16'), XY_train.loc[:, 'normal':'obscenity'].values,\n",
    "          epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503708249382609"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_score = model.predict_proba(X_test_lemmatised.astype('float16')),\n",
    "                        y_true = XY_test.loc[:, 'normal':'obscenity'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans = TfidfVectorizer(min_df = 3)\n",
    "# X_train = trans.fit_transform(XY.text)\n",
    "# X_test = trans.transform(X_final_test.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
