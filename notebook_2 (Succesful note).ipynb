{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>–¥–≤–æ—Ä–Ω–∏–∫–∞ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å!</td>\n",
       "      <td>–¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂</td>\n",
       "      <td>–¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>–º–æ—è —Å—Ç–∞—Ä—à–∞—è –Ω–µ–¥–µ–ª—é —à–∏–ø–µ–ª–∞, –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–ª–∞ –ø–æ–¥–∫–∏–¥...</td>\n",
       "      <td>–º–æ—è —Å—Ç–∞—Ä—à –Ω–µ–¥–µ–ª —à–∏–ø–µ–ª –Ω–µ –ø—Ä–∏–Ω–∏–º–∞ –ø–æ–¥–∫–∏–¥—ã—à –∫–æ—Ç–æ...</td>\n",
       "      <td>–º–æ–π —Å—Ç–∞—Ä—à–∏–π –Ω–µ–¥–µ–ª—è —à–∏–ø–µ—Ç—å –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –ø–æ–¥–∫–∏–¥—ã...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤–∞–º–∏ —Å–æ–≥–ª–∞—Å–Ω–∞!</td>\n",
       "      <td>–ø–æ–ª–Ω–æ—Å—Ç —Å –≤–∞–º —Å–æ–≥–ª–∞—Å–Ω</td>\n",
       "      <td>–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤—ã —Å–æ–≥–ª–∞—Å–Ω—ã–π</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     –¥–≤–æ—Ä–Ω–∏–∫–∞ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å!   \n",
       "1   6812  –º–æ—è —Å—Ç–∞—Ä—à–∞—è –Ω–µ–¥–µ–ª—é —à–∏–ø–µ–ª–∞, –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–ª–∞ –ø–æ–¥–∫–∏–¥...   \n",
       "2   6256                         –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤–∞–º–∏ —Å–æ–≥–ª–∞—Å–Ω–∞!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          –¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂   \n",
       "1  –º–æ—è —Å—Ç–∞—Ä—à –Ω–µ–¥–µ–ª —à–∏–ø–µ–ª –Ω–µ –ø—Ä–∏–Ω–∏–º–∞ –ø–æ–¥–∫–∏–¥—ã—à –∫–æ—Ç–æ...   \n",
       "2                              –ø–æ–ª–Ω–æ—Å—Ç —Å –≤–∞–º —Å–æ–≥–ª–∞—Å–Ω   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       –¥–≤–æ—Ä–Ω–∏–∫ –Ω–∞–¥–æ —Ç–æ–∂–µ —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å       0       1       0   \n",
       "1  –º–æ–π —Å—Ç–∞—Ä—à–∏–π –Ω–µ–¥–µ–ª—è —à–∏–ø–µ—Ç—å –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –ø–æ–¥–∫–∏–¥—ã...       1       0       0   \n",
       "2                           –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –≤—ã —Å–æ–≥–ª–∞—Å–Ω—ã–π       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 8), (18547, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_easy(model, XY, label, norm = None):\n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        predictions = model.predict_proba(XY.text_lemmatised)[:, 1]\n",
    "    elif norm == 'stem':\n",
    "        predictions = model.predict_proba(XY.text_stemmed)[:, 1]\n",
    "    else:\n",
    "        predictions = model.predict_proba(XY.text)[:, 1]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def easy_model(XY, label, norm = None):\n",
    "    pipe = Pipeline([('trans', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegressionCV(Cs = 50, scoring = 'average_precision'))])\n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        pipe.fit(XY.text_lemmatised, XY[label])\n",
    "    elif norm == 'stem':\n",
    "        pipe.fit(XY.text_stemmed, XY[label])\n",
    "    else:\n",
    "        pipe.fit(XY.text, XY[label])\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def easy_model_with_bagging(XY, label, C = 1, norm = None):\n",
    "    pipe = Pipeline([('trans', TfidfVectorizer()),\n",
    "                     ('clf', BaggingClassifier(base_estimator = LogisticRegression(C = C),\n",
    "                                               n_estimators = 100, max_samples = 0.8, random_state = 42))])\n",
    "    if norm == 'lemma':\n",
    "        pipe.fit(XY.text_lemmatised, XY[label])\n",
    "    elif norm == 'stem':\n",
    "        pipe.fit(XY.text_stemmed, XY[label])\n",
    "    else:\n",
    "        pipe.fit(XY.text, XY[label])\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def middle_model(XY, y_preds, label, norm = None):\n",
    "    \n",
    "    trans = TfidfVectorizer()\n",
    "    scaler = StandardScaler()\n",
    "    clf = LogisticRegressionCV(Cs = 10, scoring = 'average_precision') # class_weight = 'balanced', \n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        X_text = trans.fit_transform(XY.text_lemmatised)\n",
    "    elif norm == 'stem':\n",
    "        X_text = trans.fit_transform(XY.text_stemmed)\n",
    "    else:\n",
    "        X_text = trans.fit_transform(XY.text)\n",
    "    \n",
    "    X = hstack([X_text, scaler.fit_transform(y_preds)]) if y_preds is not None else X_text\n",
    "    \n",
    "    clf.fit(X, XY[label])\n",
    "    \n",
    "    return (trans, scaler, clf)\n",
    "\n",
    "def predict_middle(pipeline, XY, y_preds, label, lemma = True):\n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        X_text = pipeline[0].transform(XY.text_lemmatised)\n",
    "    elif norm == 'stem':\n",
    "        X_text = pipeline[0].transform(XY.text_stemmed)\n",
    "    else:\n",
    "        X_text = pipeline[0].transform(XY.text)\n",
    "    \n",
    "    X = hstack([X_text, pipeline[1].transform(y_preds)]) if y_preds is not None else X_text\n",
    "    \n",
    "    predictions = pipeline[2].predict_proba(X)[:, 1]\n",
    "    \n",
    "    return predictions.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c61502345d54935ba94807e39bfe44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algs_1 = dict()\n",
    "for label in tqdm(['normal', 'insult', 'obscenity', 'threat']):\n",
    "    algs_1[label] = easy_model(XY_train, label, norm = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999995112883777\n",
      "0.8842803881293029\n"
     ]
    }
   ],
   "source": [
    "print(average_precision_score(y_true = XY_train.loc[:, list(algs_1.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_1[label], XY_train, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_1.keys())]),\n",
    "                              average = 'macro'))\n",
    "\n",
    "print(average_precision_score(y_true = XY_test.loc[:, list(algs_1.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_1[label], XY_test, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_1.keys())]),\n",
    "                              average = 'macro'))\n",
    "# min_df = 1 (–ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ min_df –∫–∞—á–µ—Å—Ç–≤–æ —É—Ö—É–¥—à–∞–ª–æ—Å—å) –ø—Ä–∏ Cs = 10\n",
    "# 0.9989094360279609\n",
    "# 0.8994449421853303\n",
    "# min_df = 1 (–ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ min_df –∫–∞—á–µ—Å—Ç–≤–æ —É—Ö—É–¥—à–∞–ª–æ—Å—å) –ø—Ä–∏ Cs = 25\n",
    "# 0.9989016018343937\n",
    "# 0.8999228739030766\n",
    "# {'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = {'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}\n",
    "Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f723418456954646afdb68f563e48ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algs_2 = dict()\n",
    "for label in tqdm(['normal', 'insult', 'obscenity', 'threat']):\n",
    "    algs_2[label] = easy_model_with_bagging(XY_train, label, C = Cs[label], norm = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977239305853635\n",
      "0.8993253485125248\n"
     ]
    }
   ],
   "source": [
    "print(average_precision_score(y_true = XY_train.loc[:, list(algs_2.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_2[label], XY_train, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_2.keys())]),\n",
    "                              average = 'macro'))\n",
    "\n",
    "print(average_precision_score(y_true = XY_test.loc[:, list(algs_2.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_2[label], XY_test, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_2.keys())]),\n",
    "                              average = 'macro'))\n",
    "# 0.9977239305853635\n",
    "# 0.8993253485125248 –≤–∏–¥–∏–º–æ –±—ç–≥–≥–∏–Ω–≥ –Ω–µ —Å–∏–ª—å–Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç, –∑–∞–≤—Ç—Ä–∞ –ø–æ–ø—Ä–æ–±—É—é —Å–Ω–∏–∑–∏—Ç—å max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f36337d9834b57a1d9d3bc3d61774f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algs_4 = dict()\n",
    "st = True\n",
    "preds_train_labels = None # XY_train.id.astype('int').values.reshape(-1, 1)\n",
    "preds_test_labels = None # XY_test.id.astype('int').values.reshape(-1, 1)\n",
    "for label in tqdm(['normal', 'insult', 'threat', 'obscenity']):\n",
    "#     algs_4[label] = middle_model(XY_train, preds_train_labels[:, :1], label, lemma = st)\n",
    "    if label == 'normal':\n",
    "        algs_4[label] = middle_model(XY_train, None, label, lemma = st)\n",
    "        preds_train_labels = predict_middle(algs_4[label], XY_train, None, label, lemma = st)\n",
    "        preds_test_labels = predict_middle(algs_4[label], XY_test, None, label, lemma = st)\n",
    "    else:\n",
    "        algs_4[label] = middle_model(XY_train, preds_train_labels, label, lemma = st)\n",
    "        preds_train_labels = np.hstack([preds_train_labels, predict_middle(algs_4[label], XY_train,\n",
    "                                                                           preds_train_labels,\n",
    "                                                                           label, lemma = st)])\n",
    "        preds_test_labels = np.hstack([preds_test_labels, predict_middle(algs_4[label], XY_test,\n",
    "                                                                         preds_test_labels,\n",
    "                                                                         label, lemma = st)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661960724174861"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true = XY_train.loc[:, algs_4.keys()], y_score = preds_train_labels) # 0.9863651181168624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8740037830570584"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true = XY_test.loc[:, algs_4.keys()], y_score = preds_test_labels) # 0.8783407636309197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8945224269407825"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true = XY_test.loc[:, 'insult'], y_score = preds_test_labels[:, 1]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8667308183251967 0.0001, 0.9999, (1, 2)\n",
    "# 0.8698880391021648 0.00005, 0.99995, (1, 2)\n",
    "# 0.8717028592584694 - - -\n",
    "# 0.8753309379947046 0.00005, 0.99990, (1, 2)\n",
    "# –Ω–µ –±—ã–ª–æ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤, —Ç–µ–ø–µ—Ä—å –µ—Å—Ç—å\n",
    "# 0.8717310060366801 0.00005, 0.99990, (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public: 0.8863923769191875 (easy model)\n",
    "### Public: 0.8990635497945589 (easy model with appropriate scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>–∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—å!!!üòç</td>\n",
       "      <td>–∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—åüòç</td>\n",
       "      <td>–∫–∞–∫–æ–π –ø—Ä–µ–ª–µ—Å—Ç—åüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>–∫–∞–∞–ª –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å—é?</td>\n",
       "      <td>–∫–∞–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤</td>\n",
       "      <td>–∫–∞–∞–ª–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>–≥–Ω–æ–π–Ω—ã–µ –ø–∏–¥–æ—Ä—ã –∞–ª–ª—ã –æ–Ω–∏</td>\n",
       "      <td>–≥–Ω–æ–π–Ω –ø–∏–¥–æ—Ä –∞–ª–ª –æ–Ω–∏</td>\n",
       "      <td>–≥–Ω–æ–π–Ω—ã–π –ø–∏–¥–æ—Ä –∞–ª–ª–∞ –æ–Ω–∏</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     text         text_stemmed  \\\n",
       "0  167315       –∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—å!!!üòç      –∫–∞–∫–∞—è –ø—Ä–µ–ª–µ—Å—Ç—åüòç   \n",
       "1  224546  –∫–∞–∞–ª –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å—é?  –∫–∞–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤   \n",
       "2  241309  –≥–Ω–æ–π–Ω—ã–µ –ø–∏–¥–æ—Ä—ã –∞–ª–ª—ã –æ–Ω–∏  –≥–Ω–æ–π–Ω –ø–∏–¥–æ—Ä –∞–ª–ª –æ–Ω–∏   \n",
       "\n",
       "          text_lemmatised  \n",
       "0         –∫–∞–∫–æ–π –ø—Ä–µ–ª–µ—Å—Ç—åüòç  \n",
       "1  –∫–∞–∞–ª–∞ –∫–∞–∫–æ–π –Ω–µ —Å –∫—Ä–æ–≤—å  \n",
       "2  –≥–Ω–æ–π–Ω—ã–π –ø–∏–¥–æ—Ä –∞–ª–ª–∞ –æ–Ω–∏  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)\n",
    "X_final_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cs = {'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}\n",
    "algs_final = dict()\n",
    "for label in tqdm(['normal', 'insult', 'obscenity', 'threat']):\n",
    "    algs_final[label] = easy_model_with_bagging(XY, label, C = Cs[label], stem = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_true = XY.loc[:, list(algs_final.keys())], \n",
    "                        y_score = np.hstack([predict_easy(algs_final[label], XY, label, stem = False).reshape(-1, 1)\n",
    "                                             for label in list(algs_final.keys())]), \n",
    "                        average = 'macro')\n",
    "# check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.hstack([predict_easy(algs_final[label], X_final_test, label, stem = False).reshape(-1, 1)\n",
    "                         for label in list(algs_final.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = pd.concat([pd.DataFrame(X_final_test.id.values, columns = ['id']),\n",
    "                               pd.DataFrame(predictions, columns = list(algs_final.keys()))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_predictions.loc[:, ['id', 'normal', 'insult', 'obscenity', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
