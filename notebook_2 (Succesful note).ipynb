{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>дворника надо тоже уничтожить!</td>\n",
       "      <td>дворник надо тоже уничтож</td>\n",
       "      <td>дворник надо тоже уничтожить</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>моя старшая неделю шипела, не принимала подкид...</td>\n",
       "      <td>моя старш недел шипел не принима подкидыш кото...</td>\n",
       "      <td>мой старший неделя шипеть не принимать подкиды...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>полностью с вами согласна!</td>\n",
       "      <td>полност с вам согласн</td>\n",
       "      <td>полностью с вы согласный</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     дворника надо тоже уничтожить!   \n",
       "1   6812  моя старшая неделю шипела, не принимала подкид...   \n",
       "2   6256                         полностью с вами согласна!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          дворник надо тоже уничтож   \n",
       "1  моя старш недел шипел не принима подкидыш кото...   \n",
       "2                              полност с вам согласн   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       дворник надо тоже уничтожить       0       1       0   \n",
       "1  мой старший неделя шипеть не принимать подкиды...       1       0       0   \n",
       "2                           полностью с вы согласный       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 8), (18547, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_easy(model, XY, label, norm = None):\n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        predictions = model.predict_proba(XY.text_lemmatised)[:, 1]\n",
    "    elif norm == 'stem':\n",
    "        predictions = model.predict_proba(XY.text_stemmed)[:, 1]\n",
    "    else:\n",
    "        predictions = model.predict_proba(XY.text)[:, 1]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def easy_model(XY, label, norm = None):\n",
    "    pipe = Pipeline([('trans', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegressionCV(Cs = 50, scoring = 'average_precision'))])\n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        pipe.fit(XY.text_lemmatised, XY[label])\n",
    "    elif norm == 'stem':\n",
    "        pipe.fit(XY.text_stemmed, XY[label])\n",
    "    else:\n",
    "        pipe.fit(XY.text, XY[label])\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def easy_model_with_bagging(XY, label, C = 1, norm = None):\n",
    "    pipe = Pipeline([('trans', TfidfVectorizer()),\n",
    "                     ('clf', BaggingClassifier(base_estimator = LogisticRegression(C = C),\n",
    "                                               n_estimators = 100, max_samples = 0.8, random_state = 42))])\n",
    "    if norm == 'lemma':\n",
    "        pipe.fit(XY.text_lemmatised, XY[label])\n",
    "    elif norm == 'stem':\n",
    "        pipe.fit(XY.text_stemmed, XY[label])\n",
    "    else:\n",
    "        pipe.fit(XY.text, XY[label])\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def middle_model(XY, y_preds, label, norm = None):\n",
    "    \n",
    "    trans = TfidfVectorizer()\n",
    "    scaler = StandardScaler()\n",
    "    clf = LogisticRegressionCV(Cs = 10, scoring = 'average_precision') # class_weight = 'balanced', \n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        X_text = trans.fit_transform(XY.text_lemmatised)\n",
    "    elif norm == 'stem':\n",
    "        X_text = trans.fit_transform(XY.text_stemmed)\n",
    "    else:\n",
    "        X_text = trans.fit_transform(XY.text)\n",
    "    \n",
    "    X = hstack([X_text, scaler.fit_transform(y_preds)]) if y_preds is not None else X_text\n",
    "    \n",
    "    clf.fit(X, XY[label])\n",
    "    \n",
    "    return (trans, scaler, clf)\n",
    "\n",
    "def predict_middle(pipeline, XY, y_preds, label, lemma = True):\n",
    "    \n",
    "    if norm == 'lemma':\n",
    "        X_text = pipeline[0].transform(XY.text_lemmatised)\n",
    "    elif norm == 'stem':\n",
    "        X_text = pipeline[0].transform(XY.text_stemmed)\n",
    "    else:\n",
    "        X_text = pipeline[0].transform(XY.text)\n",
    "    \n",
    "    X = hstack([X_text, pipeline[1].transform(y_preds)]) if y_preds is not None else X_text\n",
    "    \n",
    "    predictions = pipeline[2].predict_proba(X)[:, 1]\n",
    "    \n",
    "    return predictions.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c61502345d54935ba94807e39bfe44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algs_1 = dict()\n",
    "for label in tqdm(['normal', 'insult', 'obscenity', 'threat']):\n",
    "    algs_1[label] = easy_model(XY_train, label, norm = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999995112883777\n",
      "0.8842803881293029\n"
     ]
    }
   ],
   "source": [
    "print(average_precision_score(y_true = XY_train.loc[:, list(algs_1.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_1[label], XY_train, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_1.keys())]),\n",
    "                              average = 'macro'))\n",
    "\n",
    "print(average_precision_score(y_true = XY_test.loc[:, list(algs_1.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_1[label], XY_test, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_1.keys())]),\n",
    "                              average = 'macro'))\n",
    "# min_df = 1 (при увеличении min_df качество ухудшалось) при Cs = 10\n",
    "# 0.9989094360279609\n",
    "# 0.8994449421853303\n",
    "# min_df = 1 (при увеличении min_df качество ухудшалось) при Cs = 25\n",
    "# 0.9989016018343937\n",
    "# 0.8999228739030766\n",
    "# {'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = {'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}\n",
    "Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f723418456954646afdb68f563e48ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algs_2 = dict()\n",
    "for label in tqdm(['normal', 'insult', 'obscenity', 'threat']):\n",
    "    algs_2[label] = easy_model_with_bagging(XY_train, label, C = Cs[label], norm = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977239305853635\n",
      "0.8993253485125248\n"
     ]
    }
   ],
   "source": [
    "print(average_precision_score(y_true = XY_train.loc[:, list(algs_2.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_2[label], XY_train, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_2.keys())]),\n",
    "                              average = 'macro'))\n",
    "\n",
    "print(average_precision_score(y_true = XY_test.loc[:, list(algs_2.keys())],\n",
    "                              y_score = np.hstack([predict_easy(algs_2[label], XY_test, \n",
    "                                                                label, norm = None).reshape(-1, 1)\n",
    "                                                   for label in list(algs_2.keys())]),\n",
    "                              average = 'macro'))\n",
    "# 0.9977239305853635\n",
    "# 0.8993253485125248 видимо бэггинг не сильно помогает, завтра попробую снизить max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f36337d9834b57a1d9d3bc3d61774f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "algs_4 = dict()\n",
    "st = True\n",
    "preds_train_labels = None # XY_train.id.astype('int').values.reshape(-1, 1)\n",
    "preds_test_labels = None # XY_test.id.astype('int').values.reshape(-1, 1)\n",
    "for label in tqdm(['normal', 'insult', 'threat', 'obscenity']):\n",
    "#     algs_4[label] = middle_model(XY_train, preds_train_labels[:, :1], label, lemma = st)\n",
    "    if label == 'normal':\n",
    "        algs_4[label] = middle_model(XY_train, None, label, lemma = st)\n",
    "        preds_train_labels = predict_middle(algs_4[label], XY_train, None, label, lemma = st)\n",
    "        preds_test_labels = predict_middle(algs_4[label], XY_test, None, label, lemma = st)\n",
    "    else:\n",
    "        algs_4[label] = middle_model(XY_train, preds_train_labels, label, lemma = st)\n",
    "        preds_train_labels = np.hstack([preds_train_labels, predict_middle(algs_4[label], XY_train,\n",
    "                                                                           preds_train_labels,\n",
    "                                                                           label, lemma = st)])\n",
    "        preds_test_labels = np.hstack([preds_test_labels, predict_middle(algs_4[label], XY_test,\n",
    "                                                                         preds_test_labels,\n",
    "                                                                         label, lemma = st)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661960724174861"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true = XY_train.loc[:, algs_4.keys()], y_score = preds_train_labels) # 0.9863651181168624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8740037830570584"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true = XY_test.loc[:, algs_4.keys()], y_score = preds_test_labels) # 0.8783407636309197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8945224269407825"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true = XY_test.loc[:, 'insult'], y_score = preds_test_labels[:, 1]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8667308183251967 0.0001, 0.9999, (1, 2)\n",
    "# 0.8698880391021648 0.00005, 0.99995, (1, 2)\n",
    "# 0.8717028592584694 - - -\n",
    "# 0.8753309379947046 0.00005, 0.99990, (1, 2)\n",
    "# не было баланса классов, теперь есть\n",
    "# 0.8717310060366801 0.00005, 0.99990, (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public: 0.8863923769191875 (easy model)\n",
    "### Public: 0.8990635497945589 (easy model with appropriate scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>какая прелесть!!!😍</td>\n",
       "      <td>какая прелесть😍</td>\n",
       "      <td>какой прелесть😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>каал какой не с кровью?</td>\n",
       "      <td>каа какой не с кров</td>\n",
       "      <td>каала какой не с кровь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>гнойные пидоры аллы они</td>\n",
       "      <td>гнойн пидор алл они</td>\n",
       "      <td>гнойный пидор алла они</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     text         text_stemmed  \\\n",
       "0  167315       какая прелесть!!!😍      какая прелесть😍   \n",
       "1  224546  каал какой не с кровью?  каа какой не с кров   \n",
       "2  241309  гнойные пидоры аллы они  гнойн пидор алл они   \n",
       "\n",
       "          text_lemmatised  \n",
       "0         какой прелесть😍  \n",
       "1  каала какой не с кровь  \n",
       "2  гнойный пидор алла они  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)\n",
    "X_final_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cs = {'normal': 10, 'insult': 22, 'obscenity': 464, 'threat': 22}\n",
    "algs_final = dict()\n",
    "for label in tqdm(['normal', 'insult', 'obscenity', 'threat']):\n",
    "    algs_final[label] = easy_model_with_bagging(XY, label, C = Cs[label], stem = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_true = XY.loc[:, list(algs_final.keys())], \n",
    "                        y_score = np.hstack([predict_easy(algs_final[label], XY, label, stem = False).reshape(-1, 1)\n",
    "                                             for label in list(algs_final.keys())]), \n",
    "                        average = 'macro')\n",
    "# check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.hstack([predict_easy(algs_final[label], X_final_test, label, stem = False).reshape(-1, 1)\n",
    "                         for label in list(algs_final.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = pd.concat([pd.DataFrame(X_final_test.id.values, columns = ['id']),\n",
    "                               pd.DataFrame(predictions, columns = list(algs_final.keys()))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_predictions.loc[:, ['id', 'normal', 'insult', 'obscenity', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
