{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "srmZrir30OL5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "ZzKSezAp0OMJ",
    "outputId": "93852034-0e37-4273-c11d-2de43a378543",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>дворника надо тоже уничтожить!</td>\n",
       "      <td>дворник надо тоже уничтож</td>\n",
       "      <td>дворник надо тоже уничтожить</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>моя старшая неделю шипела, не принимала подкид...</td>\n",
       "      <td>моя старш недел шипел не принима подкидыш кото...</td>\n",
       "      <td>мой старший неделя шипеть не принимать подкиды...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>полностью с вами согласна!</td>\n",
       "      <td>полност с вам согласн</td>\n",
       "      <td>полностью с вы согласный</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     дворника надо тоже уничтожить!   \n",
       "1   6812  моя старшая неделю шипела, не принимала подкид...   \n",
       "2   6256                         полностью с вами согласна!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          дворник надо тоже уничтож   \n",
       "1  моя старш недел шипел не принима подкидыш кото...   \n",
       "2                              полност с вам согласн   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       дворник надо тоже уничтожить       0       1       0   \n",
       "1  мой старший неделя шипеть не принимать подкиды...       1       0       0   \n",
       "2                           полностью с вы согласный       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KCI2T-A0OMT",
    "outputId": "f130e329-2974-4ac2-f735-629b64c0cbdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 10), (18547, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY['exclamation_num'] = XY.text.str.count('!')\n",
    "XY['question_num'] = XY.text.str.count('\\?')\n",
    "\n",
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['быдло',\n",
    " 'дрочить',\n",
    " 'кончить',\n",
    " 'отрезать',\n",
    " 'ебал',\n",
    " 'пиздец',\n",
    " 'вдуть',\n",
    " 'полизать',\n",
    " 'соснуть',\n",
    " 'повесить',\n",
    " 'утопить',\n",
    " 'пизда',\n",
    " 'сперма',\n",
    " 'козёл',\n",
    " 'пидорас',\n",
    " 'набить',\n",
    " 'говно',\n",
    " 'закопать',\n",
    " 'хохол',\n",
    " 'вор',\n",
    " 'дура',\n",
    " 'ублюдок',\n",
    " 'казнить',\n",
    " 'выебал',\n",
    " 'лизать',\n",
    " 'засадить',\n",
    " 'чмо',\n",
    " 'растрела',\n",
    " 'задница',\n",
    " 'прилюдно',\n",
    " 'гнида',\n",
    " 'сука',\n",
    " 'растрелять',\n",
    " 'насосать',\n",
    " 'сосать сосать',\n",
    " 'пиздить',\n",
    " 'проклятый',\n",
    " 'бить',\n",
    " 'отстреливать',\n",
    " 'ебу',\n",
    " 'убивать',\n",
    " 'конченый',\n",
    " 'животное',\n",
    " 'секс',\n",
    " 'блядь',\n",
    " 'шлюха',\n",
    " 'очко',\n",
    " 'фашист',\n",
    " 'ебета',\n",
    " 'отрубить',\n",
    " 'пососать',\n",
    " 'сдохнуть',\n",
    " 'стрелять',\n",
    " 'уничтожать',\n",
    " 'рак',\n",
    " 'сжечь',\n",
    " 'гад',\n",
    " 'сиська',\n",
    " 'ёбаный',\n",
    " 'прибить',\n",
    " 'трахат',\n",
    " 'дебил',\n",
    " 'шалавый',\n",
    " 'растреливать',\n",
    " 'негр',\n",
    " 'отсасывать',\n",
    " 'оторвать',\n",
    " 'хер',\n",
    " 'урод',\n",
    " 'пидарас',\n",
    " 'кастрировать',\n",
    " 'поп',\n",
    " 'пристрелить',\n",
    " 'падло',\n",
    " 'трахнуть',\n",
    " 'засунуть',\n",
    " 'морда',\n",
    " 'выебать',\n",
    " 'жопа',\n",
    " 'срак',\n",
    " 'живьём',\n",
    " 'хуйня',\n",
    " 'мочить',\n",
    " 'расстрелять',\n",
    " 'ад',\n",
    " 'расстрел',\n",
    " 'ебут',\n",
    " 'уничтожить',\n",
    " 'подвесить',\n",
    " 'гандон',\n",
    " 'мразь',\n",
    " 'подрочить',\n",
    " 'расстреливать',\n",
    " 'бля',\n",
    " 'отлизать',\n",
    " 'ебануть',\n",
    " 'вешать',\n",
    " 'хуй сосать',\n",
    " 'гореть',\n",
    " 'кол',\n",
    " 'пидор',\n",
    " 'сволочь',\n",
    " 'идиот',\n",
    " 'ебать',\n",
    " 'петух',\n",
    " 'пися',\n",
    " 'ротик',\n",
    " 'попка',\n",
    " 'хрен',\n",
    " 'сучка',\n",
    " 'наказать',\n",
    " 'хуй',\n",
    " 'долбоеб',\n",
    " 'дырка',\n",
    " 'сосать хуй',\n",
    " 'точно',\n",
    " 'нахуй',\n",
    " 'тупой',\n",
    " 'вонючий',\n",
    " 'трахаться',\n",
    " 'трахать',\n",
    " 'тварь',\n",
    " 'рожа',\n",
    " 'член',\n",
    " 'гореть ад',\n",
    " 'отсосать',\n",
    " 'долбоести',\n",
    " 'сосать',\n",
    " 'пидар',\n",
    " 'убить',\n",
    " 'смерть']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GTRux1Go0OMg"
   },
   "outputs": [],
   "source": [
    "def hyperopt_tdidf_logit_label(label):\n",
    "    \n",
    "    X_u = XY_train.text\n",
    "    X_l = XY_train.text_lemmatised\n",
    "    y = XY_train[label]\n",
    "    \n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def hyperopt_tdidf_logit(params):\n",
    "        \n",
    "        X_1 = TfidfVectorizer(min_df = int(params['min_df']), ngram_range = (1, 1)).fit_transform(X_u)\n",
    "        X_2 = CountVectorizer(vocabulary = vocab, binary = True).fit_transform(X_l)\n",
    "        \n",
    "        X = hstack([X_1, X_2])\n",
    "        \n",
    "        score = cross_val_score(estimator = LogisticRegression(C = params['C']), X = X, y = y,\n",
    "                                cv = StratifiedKFold(n_splits = 7), scoring = 'average_precision')\n",
    "\n",
    "        score_mean = score.mean()\n",
    "        \n",
    "        return -score_mean\n",
    "\n",
    "    space_tfidf_logit = {'C': hp.uniform('C', 0.1, 25),\n",
    "                         'min_df': hp.quniform('min_df', 2, 12, 1)}\n",
    "    \n",
    "    best = fmin(fn = hyperopt_tdidf_logit, space = space_tfidf_logit, algo = tpe.suggest, max_evals = 75)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(min_df = int(best['min_df']), ngram_range = (1, 1))\n",
    "    count = CountVectorizer(vocabulary = vocab, binary = True)\n",
    "    \n",
    "    X_1 = tfidf.fit_transform(X_u)\n",
    "    X_2 = count.fit_transform(X_l)\n",
    "    \n",
    "    X = hstack([X_1, X_2])\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    \n",
    "    ls = LogisticRegression(C = best['C'])\n",
    "    \n",
    "    ls.fit(X, y)\n",
    "    \n",
    "    print(average_precision_score(y_score = ls.predict_proba(X)[:, 1], y_true = y))\n",
    "    \n",
    "    return {'tf': tfidf, 'coun': count, 'logit': ls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlRwm1Vh0OMm",
    "outputId": "ef24e8fe-53db-46c3-84ec-c97061d710d4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "normal\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "100%|██████████| 50/50 [11:29<00:00, 13.78s/trial, best loss: -0.9939286414522565]\n",
      "0.9991902153444302\n",
      "----------------------------------------------------------------------------------------------------\n",
      "insult\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "100%|██████████| 50/50 [11:59<00:00, 14.38s/trial, best loss: -0.9110842515877565]\n",
      "0.9896949743792532\n",
      "----------------------------------------------------------------------------------------------------\n",
      "obscenity\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "100%|██████████| 50/50 [13:00<00:00, 15.61s/trial, best loss: -0.8042385337524033]\n",
      "0.9889213308636742\n",
      "----------------------------------------------------------------------------------------------------\n",
      "threat\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "100%|██████████| 50/50 [12:35<00:00, 15.10s/trial, best loss: -0.8877666029333326]\n",
      "0.9808049840012112\n"
     ]
    }
   ],
   "source": [
    "algs_1 = dict()\n",
    "for label in ['normal', 'insult', 'obscenity', 'threat']:\n",
    "    print('----------------------------------------------------------------------------------------------------')\n",
    "    print(label)\n",
    "    print('----------------------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    algs_1[label] = hyperopt_tdidf_logit_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJRsdRRMOQnZ",
    "outputId": "04af64bf-64b6-4feb-c2ad-1db27fae4e36",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': {'tf': TfidfVectorizer(min_df=2),\n",
       "  'coun': CountVectorizer(binary=True,\n",
       "                  vocabulary=['быдло', 'дрочить', 'кончить', 'отрезать', 'ебал',\n",
       "                              'пиздец', 'вдуть', 'полизать', 'соснуть',\n",
       "                              'повесить', 'утопить', 'пизда', 'сперма', 'козёл',\n",
       "                              'пидорас', 'набить', 'говно', 'закопать', 'хохол',\n",
       "                              'вор', 'дура', 'ублюдок', 'казнить', 'выебал',\n",
       "                              'лизать', 'засадить', 'чмо', 'растрела', 'задница',\n",
       "                              'прилюдно', ...]),\n",
       "  'logit': LogisticRegression(C=5.123683620913078)},\n",
       " 'insult': {'tf': TfidfVectorizer(min_df=2),\n",
       "  'coun': CountVectorizer(binary=True,\n",
       "                  vocabulary=['быдло', 'дрочить', 'кончить', 'отрезать', 'ебал',\n",
       "                              'пиздец', 'вдуть', 'полизать', 'соснуть',\n",
       "                              'повесить', 'утопить', 'пизда', 'сперма', 'козёл',\n",
       "                              'пидорас', 'набить', 'говно', 'закопать', 'хохол',\n",
       "                              'вор', 'дура', 'ублюдок', 'казнить', 'выебал',\n",
       "                              'лизать', 'засадить', 'чмо', 'растрела', 'задница',\n",
       "                              'прилюдно', ...]),\n",
       "  'logit': LogisticRegression(C=18.193567836867494)},\n",
       " 'obscenity': {'tf': TfidfVectorizer(min_df=2),\n",
       "  'coun': CountVectorizer(binary=True,\n",
       "                  vocabulary=['быдло', 'дрочить', 'кончить', 'отрезать', 'ебал',\n",
       "                              'пиздец', 'вдуть', 'полизать', 'соснуть',\n",
       "                              'повесить', 'утопить', 'пизда', 'сперма', 'козёл',\n",
       "                              'пидорас', 'набить', 'говно', 'закопать', 'хохол',\n",
       "                              'вор', 'дура', 'ублюдок', 'казнить', 'выебал',\n",
       "                              'лизать', 'засадить', 'чмо', 'растрела', 'задница',\n",
       "                              'прилюдно', ...]),\n",
       "  'logit': LogisticRegression(C=13.816818739210584)},\n",
       " 'threat': {'tf': TfidfVectorizer(min_df=3),\n",
       "  'coun': CountVectorizer(binary=True,\n",
       "                  vocabulary=['быдло', 'дрочить', 'кончить', 'отрезать', 'ебал',\n",
       "                              'пиздец', 'вдуть', 'полизать', 'соснуть',\n",
       "                              'повесить', 'утопить', 'пизда', 'сперма', 'козёл',\n",
       "                              'пидорас', 'набить', 'говно', 'закопать', 'хохол',\n",
       "                              'вор', 'дура', 'ублюдок', 'казнить', 'выебал',\n",
       "                              'лизать', 'засадить', 'чмо', 'растрела', 'задница',\n",
       "                              'прилюдно', ...]),\n",
       "  'logit': LogisticRegression(C=7.625769305012529)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algs_1\n",
    "# 100%|██████████| 100/100 [32:12<00:00, 19.33s/trial, best loss: -0.9052236649167692] - insult\n",
    "\n",
    "# 100%|██████████| 100/100 [36:35<00:00, 21.95s/trial, best loss: -0.8018728019201194] - obscenity\n",
    "\n",
    "# 100%|██████████| 100/100 [34:22<00:00, 20.63s/trial, best loss: -0.8884257267154007] - threat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UAexmbXV0ONc",
    "outputId": "8617ec54-4bec-4d7a-ddd2-589e23a22347",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>какая прелесть!!!😍</td>\n",
       "      <td>какая прелесть😍</td>\n",
       "      <td>какой прелесть😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>каал какой не с кровью?</td>\n",
       "      <td>каа какой не с кров</td>\n",
       "      <td>каала какой не с кровь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>гнойные пидоры аллы они</td>\n",
       "      <td>гнойн пидор алл они</td>\n",
       "      <td>гнойный пидор алла они</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                     text         text_stemmed  \\\n",
       "0  167315       какая прелесть!!!😍      какая прелесть😍   \n",
       "1  224546  каал какой не с кровью?  каа какой не с кров   \n",
       "2  241309  гнойные пидоры аллы они  гнойн пидор алл они   \n",
       "\n",
       "          text_lemmatised  \n",
       "0         какой прелесть😍  \n",
       "1  каала какой не с кровь  \n",
       "2  гнойный пидор алла они  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)\n",
    "X_final_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HuiwWJcg0ONb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# trans = TfidfVectorizer(min_df = 2)\n",
    "# text_train = trans.fit_transform(XY.text)\n",
    "# text_test = trans.transform(X_final_test.text)\n",
    "\n",
    "\n",
    "# clf_normal = LogisticRegression(C = 6.4).fit(text_train, XY['normal'])\n",
    "# clf_insult = LogisticRegression(C = 11.2).fit(text_train, XY['insult'])\n",
    "# clf_threat = LogisticRegression(C = 10.6).fit(text_train, XY['threat'])\n",
    "\n",
    "# pred_test_normal = clf_normal.predict_proba(text_test)[:, 1].reshape(-1, 1)\n",
    "# pred_test_insult = clf_insult.predict_proba(text_test)[:, 1].reshape(-1, 1)\n",
    "# pred_test_threat = clf_threat.predict_proba(text_test)[:, 1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "trans_1_normal = TfidfVectorizer(min_df = 2, ngram_range = (1, 1))\n",
    "text_1_train_normal = trans_1_normal.fit_transform(XY.text)\n",
    "text_1_test_normal = trans_1_normal.transform(X_final_test.text)\n",
    "\n",
    "trans_1_insult = TfidfVectorizer(min_df = 2, ngram_range = (1, 1))\n",
    "text_1_train_insult = trans_1_insult.fit_transform(XY.text)\n",
    "text_1_test_insult = trans_1_insult.transform(X_final_test.text)\n",
    "\n",
    "trans_1_threat = TfidfVectorizer(min_df = 3, ngram_range = (1, 1))\n",
    "text_1_train_threat = trans_1_threat.fit_transform(XY.text)\n",
    "text_1_test_threat = trans_1_threat.transform(X_final_test.text)\n",
    "\n",
    "trans_1_obscenity = TfidfVectorizer(min_df = 2, ngram_range = (1, 1))\n",
    "text_1_train_obscenity = trans_1_obscenity.fit_transform(XY.text)\n",
    "text_1_test_obscenity = trans_1_obscenity.transform(X_final_test.text)\n",
    "\n",
    "\n",
    "trans_2 = CountVectorizer(vocabulary = vocab, binary = True)\n",
    "text_2_train = trans_2.fit_transform(XY.text_lemmatised)\n",
    "text_2_test = trans_2.transform(X_final_test.text_lemmatised)\n",
    "\n",
    "\n",
    "text_train_normal = hstack([text_1_train_normal, text_2_train])\n",
    "text_train_insult = hstack([text_1_train_insult, text_2_train])\n",
    "text_train_threat = hstack([text_1_train_threat, text_2_train])\n",
    "text_train_obscenity = hstack([text_1_train_obscenity, text_2_train])\n",
    "\n",
    "text_test_normal = hstack([text_1_test_normal, text_2_test])\n",
    "text_test_insult = hstack([text_1_test_insult, text_2_test])\n",
    "text_test_threat = hstack([text_1_test_threat, text_2_test])\n",
    "text_test_obscenity = hstack([text_1_test_obscenity, text_2_test])\n",
    "\n",
    "\n",
    "clf_normal = LogisticRegression(C = 5.12).fit(text_train_normal, XY['normal'])\n",
    "clf_insult = LogisticRegression(C = 18.19).fit(text_train_insult, XY['insult'])\n",
    "clf_threat = LogisticRegression(C = 7.63).fit(text_train_threat, XY['threat']) # 19.775484\n",
    "clf_obscenity = LogisticRegression(C = 13.82).fit(text_train_obscenity, XY['obscenity']) # 20.8466131\n",
    "\n",
    "pred_test_normal = clf_normal.predict_proba(text_test_normal)[:, 1].reshape(-1, 1)\n",
    "pred_test_insult = clf_insult.predict_proba(text_test_insult)[:, 1].reshape(-1, 1)\n",
    "pred_test_threat = clf_threat.predict_proba(text_test_threat)[:, 1].reshape(-1, 1)\n",
    "pred_test_obscenity = clf_obscenity.predict_proba(text_test_obscenity)[:, 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TWbe9_sZ0ONi"
   },
   "outputs": [],
   "source": [
    "predictions = np.hstack([pred_test_normal, pred_test_insult, pred_test_threat, pred_test_obscenity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['normal', 'insult', 'threat', 'obscenity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dpk6iVIX0ONj"
   },
   "outputs": [],
   "source": [
    "final_predictions = pd.concat([pd.DataFrame(X_final_test.id.values, columns = ['id']),\n",
    "                               pd.DataFrame(predictions, columns = labels)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UbahSrcW0ONk"
   },
   "outputs": [],
   "source": [
    "result = final_predictions.loc[:, ['id', 'normal', 'insult', 'obscenity', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>normal</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>0.998261</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>0.946274</td>\n",
       "      <td>0.033348</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.030082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.019074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31170</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.015765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173358</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    normal    insult  obscenity    threat\n",
       "0  167315  0.998261  0.000232   0.000150  0.000080\n",
       "1  224546  0.946274  0.033348   0.002244  0.030082\n",
       "2  241309  0.003021  0.999378   0.001123  0.019074\n",
       "3   31170  0.000455  0.999731   0.014532  0.015765\n",
       "4  173358  0.947059  0.061836   0.004384  0.001584"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jfiODFw10ONm"
   },
   "outputs": [],
   "source": [
    "result.to_csv('result', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_6 (simple hyperopt).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
