{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "      <th>normal</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>дворника надо тоже уничтожить!</td>\n",
       "      <td>дворник надо тоже уничтож</td>\n",
       "      <td>дворник надо тоже уничтожить</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>моя старшая неделю шипела, не принимала подкид...</td>\n",
       "      <td>моя старш недел шипел не принима подкидыш кото...</td>\n",
       "      <td>мой старший неделя шипеть не принимать подкиды...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>полностью с вами согласна!</td>\n",
       "      <td>полност с вам согласн</td>\n",
       "      <td>полностью с вы согласный</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  41127                     дворника надо тоже уничтожить!   \n",
       "1   6812  моя старшая неделю шипела, не принимала подкид...   \n",
       "2   6256                         полностью с вами согласна!   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                          дворник надо тоже уничтож   \n",
       "1  моя старш недел шипел не принима подкидыш кото...   \n",
       "2                              полност с вам согласн   \n",
       "\n",
       "                                     text_lemmatised  normal  threat  insult  \\\n",
       "0                       дворник надо тоже уничтожить       0       1       0   \n",
       "1  мой старший неделя шипеть не принимать подкиды...       1       0       0   \n",
       "2                           полностью с вы согласный       1       0       0   \n",
       "\n",
       "   obscenity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY = pd.read_csv('XY.csv', header = 0)\n",
    "XY.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104142, 8), (18547, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_train, XY_test = train_test_split(XY, test_size = 0.3, shuffle = True, random_state = 42)\n",
    "XY_train.reset_index(drop = True, inplace = True)\n",
    "XY_test.reset_index(drop = True, inplace = True)\n",
    "XY_train_abn = XY_train.loc[XY_train.normal == 0, :].reset_index(drop = True)\n",
    "XY_train.shape, XY_train_abn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label predictions\n",
    "## Function manufacture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def search_best_tfidf_and_algo(X, y, ns = 3, num_of_evals = 10):\n",
    "    \n",
    "    def hyperopt_tfidf_algo_score(params):\n",
    "        try:\n",
    "            trans = TfidfVectorizer(stop_words = params['stop_words'], min_df = params['min_df'],\n",
    "                                    ngram_range = params['ngram_range'])\n",
    "            \n",
    "            if params['norm'] == 'lemma':\n",
    "                X_prep = trans.fit_transform(X.text_lemmatised) \n",
    "            elif params['norm'] == 'stem':\n",
    "                X_prep = trans.fit_transform(X.text_stemmed)\n",
    "            else:\n",
    "                X_prep = trans.fit_transform(X.text)\n",
    "            \n",
    "            clf = LogisticRegression(C = params['C'], class_weight = params['class_weight'])\n",
    "\n",
    "            current_score_scores = cross_val_score(clf, X_prep, y, cv = StratifiedKFold(n_splits = ns),\n",
    "                                                   scoring = 'average_precision')\n",
    "            \n",
    "            mean_score = np.mean(current_score_scores)\n",
    "            current_score = mean_score if np.std(current_score_scores * 100) < 1.5 else mean_score / 1.5\n",
    "            \n",
    "        except:\n",
    "            current_score = 0\n",
    "            print(f\"Bad min_df: {algo_params['min_df']}\")\n",
    "        \n",
    "        return -current_score\n",
    "        \n",
    "    space_tfidf = {\n",
    "        'min_df': hp.choice('min_df', np.arange(2, 8, 1)),\n",
    "        'stop_words': hp.choice('stop_words', [stopWords, None]),\n",
    "        'ngram_range': hp.choice('ngram_range', [(1, 1), (1, 2)]),\n",
    "        'norm': hp.choice('norm', ['lemma', 'stem', 'initial'])\n",
    "    }\n",
    "    \n",
    "    space_algo = {'C': hp.uniform('C', 10**(0), 10**(2)), \n",
    "                  'class_weight': hp.choice('class_weight', ['balanced', None])}\n",
    "    \n",
    "    space = dict(**space_tfidf, **space_algo)\n",
    "    \n",
    "    best = fmin(fn = hyperopt_tfidf_algo_score, space = space, algo = tpe.suggest, max_evals = num_of_evals)\n",
    "    \n",
    "    best['min_df'] = np.arange(1, 6, 1)[best['min_df']]\n",
    "    best['stop_words'] = [stopWords, None][best['stop_words']]\n",
    "    best['ngram_range'] = [(1, 1), (1, 2)][best['ngram_range']]\n",
    "    \n",
    "    best['norm'] = ['lemma', 'stem', 'initial'][best['norm']]\n",
    "    \n",
    "    best['class_weight'] = ['balanced', None][best['class_weight']]\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def build_best_tfidf_and_algo(params, X_train, y_train, X_valid, y_valid):\n",
    "    \n",
    "    trans = TfidfVectorizer(min_df = params['min_df'], stop_words = params['stop_words'], \n",
    "                            ngram_range = params['ngram_range'])\n",
    "    \n",
    "    if params['norm'] == 'lemma':\n",
    "        X_train_prep = trans.fit_transform(X_train.text_lemmatised)\n",
    "        X_valid_prep = trans.transform(X_valid.text_lemmatised)\n",
    "    elif params['norm'] == 'stem':\n",
    "        X_train_prep = trans.fit_transform(X_train.text_stemmed)\n",
    "        X_valid_prep = trans.transform(X_valid.text_stemmed)\n",
    "    else:\n",
    "        X_train_prep = trans.fit_transform(X_train.text)\n",
    "        X_valid_prep = trans.transform(X_valid.text)\n",
    "    \n",
    "    clf = LogisticRegression(C = params['C'], class_weight = params['class_weight'])\n",
    "    clf.fit(X_train_prep, y_train)\n",
    "    \n",
    "    aps_train = average_precision_score(y_true = y_train, y_score = clf.predict_proba(X_train_prep)[:, 1])\n",
    "    aps_valid = average_precision_score(y_true = y_valid, y_score = clf.predict_proba(X_valid_prep)[:, 1])\n",
    "    \n",
    "    return {'norm': params['norm'], 'transformer': trans, 'classifier': clf, 'scores': [aps_train, aps_valid]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_build(XY, label, balancing = True, test_size = 0.2, ns = 5, num_of_evals = 10):\n",
    "    \n",
    "    if balancing:\n",
    "        sample_num = min(XY.loc[XY[label] == 1].shape[0], XY.loc[XY[label] == 0].shape[0])\n",
    "        XY_balanced = pd.concat([XY.loc[XY[label] == 1].sample(sample_num, random_state = 42),\n",
    "                                 XY.loc[XY[label] == 0].sample(sample_num, random_state = 42)], axis = 0)\n",
    "    else:\n",
    "        XY_balanced = XY\n",
    "    \n",
    "    XY_train, XY_valid = train_test_split(XY_balanced, stratify = XY_balanced[label], test_size = test_size,\n",
    "                                          shuffle = True, random_state = 42)\n",
    "    XY_train.reset_index(drop = True, inplace = True)\n",
    "    XY_valid.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    X_train = XY_train.drop(columns = label)\n",
    "    y_train = XY_train.loc[:, label].values\n",
    "    \n",
    "    X_valid = XY_valid.drop(columns = label)\n",
    "    y_valid = XY_valid.loc[:, label].values\n",
    "    \n",
    "    params = search_best_tfidf_and_algo(X_train, y_train, ns = ns, num_of_evals = num_of_evals)\n",
    "    \n",
    "    return build_best_tfidf_and_algo(params, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monster_search(XY: pd.DataFrame, labels: list = ['normal'], balancing: list = [True], test_size: float = 0.2, \n",
    "                   ns: list = [10], num_of_evals: list = [10], final_algos: dict = {}) -> dict:\n",
    "    \n",
    "    for l, label in enumerate(labels):\n",
    "        print()\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        print(label)\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "        \n",
    "        algo_result = search_build(XY, label, balancing = balancing[l], test_size = test_size, \n",
    "                                   ns = ns[l], num_of_evals = num_of_evals[l])\n",
    "        \n",
    "        final_algos[label] = algo_result\n",
    "    \n",
    "    return final_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "normal\n",
      "---------------------------------------------------------------------------------------------------\n",
      "100%|██████████| 50/50 [05:49<00:00,  6.99s/trial, best loss: -0.9911795125105891]\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "insult\n",
      "---------------------------------------------------------------------------------------------------\n",
      "100%|██████████| 50/50 [06:14<00:00,  7.49s/trial, best loss: -0.8936379998879065]\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "obscenity\n",
      "---------------------------------------------------------------------------------------------------\n",
      "100%|██████████| 50/50 [05:27<00:00,  6.54s/trial, best loss: -0.7525734737778982] \n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "threat\n",
      "---------------------------------------------------------------------------------------------------\n",
      "100%|██████████| 50/50 [05:43<00:00,  6.88s/trial, best loss: -0.8632498774249159]\n"
     ]
    }
   ],
   "source": [
    "final_algos_1 = monster_search(XY_train, labels = ['normal', 'insult', 'obscenity', 'threat'],\n",
    "                               balancing = [False] * 4, test_size = 0.2, ns = [5] * 4, num_of_evals = [250] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_algos_1\n",
    "# {'normal': {'norm': 'stem',\n",
    "#   'transformer': TfidfVectorizer(min_df=3, ngram_range=(1, 2)),\n",
    "#   'classifier': LogisticRegression(C=43.61225142163715, class_weight='balanced'),\n",
    "#   'scores': [0.9997501061237812, 0.9906656653390087]},\n",
    "#  'insult': {'norm': 'stem',\n",
    "#   'transformer': TfidfVectorizer(min_df=4, ngram_range=(1, 2), stop_words=stopWords),\n",
    "#   'classifier': LogisticRegression(C=14.163874788479188),\n",
    "#   'scores': [0.9703978115236113, 0.9018463501179763]},\n",
    "#  'obscenity': {'norm': 'initial',\n",
    "#   'transformer': TfidfVectorizer(min_df=2),\n",
    "#   'classifier': LogisticRegression(C=41.88942360620957),\n",
    "#   'scores': [0.9920524059927307, 0.752306287824738]},\n",
    "#  'threat': {'norm': 'initial',\n",
    "#   'transformer': TfidfVectorizer(min_df=10, ngram_range=(1, 2)),\n",
    "#   'classifier': LogisticRegression(C=2.047808035445657),\n",
    "#   'scores': [0.9337172577508484, 0.8503346208600301]}}\n",
    "\n",
    "{'normal': {'classifier': LogisticRegression(C = 9, class_weight = 'balanced'),\n",
    "            'norm': 'stem',\n",
    "            'scores': [0.9998298284695576, 0.9929094934296164],\n",
    "            'transformer': TfidfVectorizer(min_df = 1, ngram_range = (1, 1))},\n",
    " 'insult': {'classifier': LogisticRegression(C = 10, class_weight = None),\n",
    "            'norm': 'initial',\n",
    "            'scores': [0.9866985845174877, 0.9050294725010097],\n",
    "            'transformer': TfidfVectorizer(min_df = 2, ngram_range = (1, 1))},\n",
    " 'obscenity': {'classifier': LogisticRegression(C = 94, class_weight = None),\n",
    "               'norm': 'lemma',\n",
    "               'scores': [0.9901362947613137, 0.7137456145906628],\n",
    "               'transformer': TfidfVectorizer(min_df = 2, ngram_range = (1, 2), stop_words = stopWords)},\n",
    " 'threat': {'classifier': LogisticRegression(C = 14, class_weight = None),\n",
    "            'norm': 'initial',\n",
    "            'scores': [0.9896822419756792, 0.8677644706078192],\n",
    "            'transformer': TfidfVectorizer(min_df = 3, ngram_range = (1, 1))}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_predictions(data, algos):\n",
    "    \n",
    "    if algos['normal']['norm'] == 'lemma':\n",
    "        X_train_n = algos['normal']['transformer'].transform(data.text_lemmatised)\n",
    "    elif algos['normal']['norm'] == 'stem':\n",
    "        X_train_n = algos['normal']['transformer'].transform(data.text_stemmed)\n",
    "    else:\n",
    "        X_train_n = algos['normal']['transformer'].transform(data.text)\n",
    "    \n",
    "    preds = algos['normal']['classifier'].predict_proba(X_train_n)[:, 1].reshape(-1, 1)\n",
    "    predicted_labels_n = np.abs(algos['normal']['classifier'].predict(X_train_n) - 1).reshape(-1, 1)\n",
    "    \n",
    "    for label, algo in [(key, value) for key, value in algos.items() if key != 'normal']:\n",
    "        \n",
    "        if algo['norm'] == 'lemma':\n",
    "            X_train_abn = algo['transformer'].transform(data.text_lemmatised)\n",
    "        elif algo['norm'] == 'stem':\n",
    "            X_train_abn = algo['transformer'].transform(data.text_stemmed)\n",
    "        else:\n",
    "            X_train_abn = algo['transformer'].transform(data.text)\n",
    "        \n",
    "        preds_abn = algo['classifier'].predict_proba(X_train_abn)[:, 1].reshape(-1, 1) #* predicted_labels_n\n",
    "        preds = np.concatenate([preds, preds_abn], axis = 1)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictions = get_prob_predictions(XY_train, final_algos_1)\n",
    "# average_precision_score(y_true = XY_train.loc[:, list(final_algos_1.keys())],\n",
    "#                         y_score = predictions, average = 'macro') # 0.9565494854057154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = get_prob_predictions(XY_test, final_algos_1)\n",
    "# average_precision_score(y_true = XY_test.loc[:, list(final_algos_1.keys())], \n",
    "#                         y_score = predictions, average = 'macro') # 0.8762971108666133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167315</td>\n",
       "      <td>какая прелесть!!!😍</td>\n",
       "      <td>какая прелесть😍</td>\n",
       "      <td>какой прелесть😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224546</td>\n",
       "      <td>каал какой не с кровью?</td>\n",
       "      <td>каа какой не с кров</td>\n",
       "      <td>каала какой не с кровь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241309</td>\n",
       "      <td>гнойные пидоры аллы они</td>\n",
       "      <td>гнойн пидор алл они</td>\n",
       "      <td>гнойный пидор алла они</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31170</td>\n",
       "      <td>чё ты губы шлёшь в помаде?фу блядь</td>\n",
       "      <td>че ты губ шлеш в помадеф бляд</td>\n",
       "      <td>что ты губа слать в помадефа блядь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173358</td>\n",
       "      <td>матрона помогает реально это правда. сама к не...</td>\n",
       "      <td>матрон помога реальн эт правд сам к ней езд на...</td>\n",
       "      <td>матрона помогать реально это правда сам к она ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0  167315                                 какая прелесть!!!😍   \n",
       "1  224546                            каал какой не с кровью?   \n",
       "2  241309                            гнойные пидоры аллы они   \n",
       "3   31170                 чё ты губы шлёшь в помаде?фу блядь   \n",
       "4  173358  матрона помогает реально это правда. сама к не...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0                                    какая прелесть😍   \n",
       "1                                каа какой не с кров   \n",
       "2                                гнойн пидор алл они   \n",
       "3                      че ты губ шлеш в помадеф бляд   \n",
       "4  матрон помога реальн эт правд сам к ней езд на...   \n",
       "\n",
       "                                     text_lemmatised  \n",
       "0                                    какой прелесть😍  \n",
       "1                             каала какой не с кровь  \n",
       "2                             гнойный пидор алла они  \n",
       "3                 что ты губа слать в помадефа блядь  \n",
       "4  матрона помогать реально это правда сам к она ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test = pd.read_csv('X_final_test.csv', header = 0)\n",
    "X_final_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_prob_predictions(X_final_test, final_algos_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame = pd.concat([pd.DataFrame(X_final_test.id.values, columns = ['id']), \n",
    "                         pd.DataFrame(predictions, columns = list(final_algos_1.keys()))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_frame.loc[:, ['id', 'normal', 'insult', 'obscenity', 'threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('result', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions = get_prob_predictions(XY, loaded_model, activates_s)\n",
    "# average_precision_score(y_true = XY.loc[:, ['normal', 'insult', 'threat', 'obscenity']],\n",
    "#                         y_score = predictions, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(final_algos, open('final_algos', 'wb'))\n",
    "# pickle.dump(activates_s, open('activates_s', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_models = pickle.load(open('final_algos', 'rb'))\n",
    "# loaded_activates_s = pickle.load(open('activates_s', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
